import os
import json
import warnings

from loguru import logger

from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage

from src.slack_integrations_online.application.agents.tools.memory_tools import search_memory, add_to_memory
from src.slack_integrations_online.application.agents.tools.mongodb_retriever_tools import mongodb_retriever_tool, get_complete_docs_with_url

warnings.filterwarnings("ignore", category=DeprecationWarning)



INSTRUCTIONS="""You are a helpful agent that uses tools to answer user queries accurately.

**Step 1: Identify User Intent**
Determine if the user is asking about their previous memories/conversations or asking a new question.

**If user is asking about memories:**
- Use search_memory tool to retrieve relevant memories
- Provide the response based on retrieved memories
- Do NOT use other tools

**If user is asking a new question:**
1. First, use search_memory to check for relevant past context
2. Use mongodb_retriever_tool to search for relevant documents
3. Answer using ONLY information from the retrieved documents
4. If the chunks lack detail, use get_complete_docs_with_url to fetch complete documents
5. Finally, use add_to_memory to store this interaction for future reference

**Guidelines:**
- Be concise and accurate
- Quote relevant parts from documents when appropriate
- If information is not found, say "I don't have enough information to answer this question"
- Always cite document URLs in your final answer at the end, when using information from documents
- Only use get_complete_docs_with_url when chunks are relevant to the query but lack sufficient detail or context
"""



model = ChatOpenAI(model="gpt-4o-mini")
tools = [search_memory, mongodb_retriever_tool, get_complete_docs_with_url, add_to_memory]


def create_agent_graph():
    """Create a LangGraph agent with tools using StateGraph."""
    
    # Bind tools to model
    model_with_tools = model.bind_tools(tools)
    logger.info(f"ğŸ“¦ Model bound with {len(tools)} tools: {[t.name for t in tools]}")
    
    # Define the function that calls the model
    def call_model(state: MessagesState):
        messages = state["messages"]
        
        # Add system message if not present or if it's the first message
        if not messages or not any(isinstance(msg, SystemMessage) for msg in messages):
            messages = [SystemMessage(content=INSTRUCTIONS)] + messages
        
        logger.info(f"ğŸ¤– Agent processing {len(messages)} messages")
        response = model_with_tools.invoke(messages)
        
        # Check if agent wants to use tools
        if hasattr(response, 'tool_calls') and response.tool_calls:
            logger.info(f"ğŸ› ï¸ Agent requested {len(response.tool_calls)} tool calls:")
            for tool_call in response.tool_calls:
                logger.info(f"   - {tool_call['name']}: {tool_call['args']}")
        else:
            logger.info(f"ğŸ’¬ Agent responding directly")
        
        return {"messages": [response]}
    
    # Build the graph
    workflow = StateGraph(MessagesState)
    
    # Add nodes
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode(tools))
    
    # Add edges
    workflow.add_edge(START, "agent")
    workflow.add_conditional_edges(
        "agent",
        tools_condition,
    )
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()


agent_graph = create_agent_graph()

logger.info("ğŸš€ Initializing agent with the following tools:")

for tool in tools:
    logger.info(f"   ğŸ”§ {tool.name}: {tool.description[:100]}...")


class SupportAgentsManager():
    """Manager for running support agents with memory context and trace logging."""
    
    def __init__(self) -> None:
        pass

    async def run(self, query: str, user_id: str = "default_user") -> str:
        try:
            logger.info(f"ğŸ¬ Starting agent for user: {user_id}")
            logger.info(f"   ğŸ“ Query: '{query}'")
            
            inputs = {"messages": [HumanMessage(content=query)]}  # Simplified message
            config = {"configurable": {"user_id": user_id}}

            result = await agent_graph.ainvoke(inputs, config=config)

            final_output = result["messages"][-1].content
            
            # Clean up the response if needed
            if final_output.startswith("**") or "**ZenML**" in final_output:
                logger.info("âœ… Agent successfully answered using MongoDB documents!")
            else:
                logger.info(f"âœ… Agent response generated")
            
            return final_output

        except Exception as e:
            logger.error(f"âŒ Error: {str(e)}")
            import traceback
            traceback.print_exc()
            return f"I encountered an error: {str(e)}"