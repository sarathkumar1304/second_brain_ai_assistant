{
    "id": "c52be9eee1fdc1c9bdddd5dbe17ff74c",
    "metadata": {
        "id": "c52be9eee1fdc1c9bdddd5dbe17ff74c",
        "url": "https://docs.zenml.io/concepts/steps_and_pipelines/configuration",
        "title": "Configuration | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Configuring and customizing your pipeline runs.",
            "keywords": null,
            "author": null,
            "og:title": "Configuration | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Configuring and customizing your pipeline runs.",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/UkRY2QeL5nKBtM2Byw8p",
            "twitter:card": "summary_large_image",
            "twitter:title": "Configuration | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Configuring and customizing your pipeline runs.",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/UkRY2QeL5nKBtM2Byw8p"
        }
    },
    "content": "`Ctrl``k`\n\nGitBook AssistantAsk\n\nProductResourcesGitHubStart free\n\nMore\n\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\n\nGitBook Assistant\n\nGitBook Assistant\n\nWorking...Thinking...\n\nGitBook Assistant\n\n##### Good evening\n\nI'm here to help you with the docs.\n\nWhat is this page about?What should I read next?Can you give an example?\n\n`Ctrl``i`\n\nAI Based on your context\n\nSend\n\n  * Getting Started\n\n    * Welcome to ZenML\n    * Installation\n    * Hello World\n    * Your First AI Pipeline\n    * Core Concepts\n    * System Architecture\n  * Deploying ZenML\n\n    * Deploy\n    * Connect\n    * Manage\n  * Concepts\n\n    * Steps & Pipelines\n\n      * Configuration\n      * Scheduling\n      * Logging\n      * YAML Configuration\n      * Source Code and Imports\n      * Advanced Features\n      * Dynamic Pipelines (Experimental)\n\n    * Artifacts\n    * Stack & Components\n    * Service Connectors\n    * Pipeline Snapshots\n    * Pipeline Deployments\n    * Containerization\n    * Code Repositories\n    * Secrets\n    * Environment Variables\n    * Tags\n    * Metadata\n    * Models\n    * Dashboard\n    * Templates\n  * Reference\n\n    * Community & content\n    * Environment Variables\n    * MCP Docs & llms.txt\n    * FAQ\n    * Global settings\n    * Legacy docs\n\n\n\nPowered by GitBook\n\nOn this page\n\n  * Approaches to Configuration\n  * Types of Settings\n  * Configuration Hierarchy\n  * Common Setting Types\n  * Stack Component Configuration\n  * Making Configurations Flexible with Environment Variables\n  * Autogenerate a template yaml file\n\n\n\nWas this helpful?\n\nGitBook AssistantAsk\n\n  1. Concepts\n  2. Steps & Pipelines\n\n\n\n# Configuration\n\nConfiguring and customizing your pipeline runs.\n\nZenML provides several approaches to configure your pipelines and steps:\n\n#### \n\nUnderstanding `.configure()` vs `.with_options()`\n\nZenML provides two primary methods to configure pipelines and steps: `.configure()` and `.with_options()`. While they accept the same parameters, they behave differently:\n\n  * `**.configure()**`: Modifies the configuration**in-place** and returns the same object.\n\n  * `**.with_options()**`: Creates a**new copy** with the applied configuration, leaving the original unchanged.\n\n\n\n\nWhen to use each:\n\n  * Use `.with_options()` in most cases, especially inside pipeline definitions:\n\nCopy```\n@pipeline\ndefmy_pipeline():\n# This creates a new configuration just for this instance\n  my_step.with_options(parameters={\"param\": \"value\"})()\n```\n\n\n  * Use `.configure()` only when you intentionally want to modify a step globally, and are aware that the change will affect all subsequent invocations of that step.\n\n\n\n\n### \n\nApproaches to Configuration\n\n#### \n\nPipeline Configuration with `configure`\n\nYou can configure various aspects of a pipeline using the `configure` method:\n\nCopy```\nfrom zenml import pipeline\n# Assuming MyPipeline is your pipeline function\n# @pipeline\n# def MyPipeline():\n#   ...\n# Create a pipeline\nmy_pipeline =MyPipeline()\n# Configure the pipeline\nmy_pipeline.configure(\n  enable_cache=False,\n  enable_artifact_metadata=True,\n  settings={\n\"docker\": {\n\"parent_image\": \"zenml-io/zenml-cuda:latest\"\n    }\n  }\n)\n# Run the pipeline\nmy_pipeline()\n```\n\n\n#### \n\nRuntime Configuration with `with_options`\n\nYou can configure a pipeline at runtime using the `with_options` method:\n\nCopy```\n# Configure specific step parameters\nmy_pipeline.with_options(steps={\"trainer\": {\"parameters\": {\"learning_rate\": 0.01}}})()\n# Or using a YAML configuration file\nmy_pipeline.with_options(config_file=\"path_to_yaml_file\")()\n```\n\n\n#### \n\nStep-Level Configuration\n\nYou can configure individual steps with the `@step` decorator:\n\nCopy```\nimport tensorflow as tf\nfrom zenml import step\n@step(\n  settings={\n    # Custom materializer for handling output serialization\n    \"output_materializers\": {\n      \"output\": \"zenml.materializers.tensorflow_materializer.TensorflowModelMaterializer\"\n    },\n    # Step-specific experiment tracker settings\n    \"experiment_tracker.mlflow\": {\n      \"experiment_name\": \"custom_experiment\"\n    }\n  }\n)\ndef train_model() -> tf.keras.Model:\n  model = build_and_train_model()\n  return model\n```\n\n\n#### \n\nDirect Component Assignment\n\nIf you have an experiment tracker or step operator in your active stack, you can enable them for specific steps like this:\n\nCopy```\nfrom zenml import step\n@step(experiment_tracker=True, step_operator=True)\ndef train_model():\n  # This step will use the experiment tracker and step operator of the active stack\n  ...\n```\n\n\nIf you want to make sure a step can only run with a specific experiment tracker/step operator, you can also specify the component names like this:\n\nCopy```\nfrom zenml import step\n@step(experiment_tracker=\"mlflow_tracker\", step_operator=\"vertex_ai\")\ndef train_model():\n  # This step will use MLflow for tracking and run on Vertex AI\n  ...\n```\n\n\nYou can combine both approaches with settings to configure the specific behavior of those components:\n\nCopy```\nfrom zenml import step\n@step(step_operator=True, settings={\"step_operator\": {\"estimator_args\": {\"instance_type\": \"m7g.medium\"}}})\ndef my_step():\n  # This step will use the step operator of the active stack with custom instance type\n  ...\n# Alternatively, using the step operator name and appropriate settings class:\n@step(step_operator=\"nameofstepoperator\", settings={\"step_operator\": SagemakerStepOperatorSettings(instance_type=\"m7g.medium\")})\ndef my_step():\n  # Same configuration using the settings class\n  ...\n```\n\n\nThis approach allows you to use different components for different steps in your pipeline while also customizing their runtime behavior.\n\n### \n\nTypes of Settings\n\nSettings in ZenML are categorized into three main types:\n\n  * **General settings** that can be used on all ZenML pipelines:\n\n    * `DockerSettings` for container configuration\n\n    * `ResourceSettings` for CPU, memory, and GPU allocation\n\n    * `DeploymentSettings` for pipeline deployment configuration - can only be set at the pipeline level\n\n  * **Stack-component-specific settings** for configuring behaviors of components in your stack:\n\n    * These use the pattern `<COMPONENT_CATEGORY>` or `<COMPONENT_CATEGORY>.<COMPONENT_FLAVOR>` as keys\n\n    * Examples include `experiment_tracker.mlflow` or just `step_operator`\n\n\n\n\n### \n\nConfiguration Hierarchy\n\nThere are a few general rules when it comes to settings and configurations that are applied in multiple places. Generally the following is true:\n\n  * Configurations in code override configurations made inside of the yaml file\n\n  * Configurations at the step level override those made at the pipeline level\n\n  * In case of attributes the dictionaries are merged\n\n\n\n\nCopy```\nfrom zenml import pipeline, step\nfrom zenml.config import ResourceSettings\n@step\ndef load_data(parameter: int) -> dict:\n  ...\n@step(settings={\"resources\": ResourceSettings(gpu_count=1, memory=\"2GB\")})\ndef train_model(data: dict) -> None:\n  ...\n@pipeline(settings={\"resources\": ResourceSettings(cpu_count=2, memory=\"1GB\")}) \ndef simple_ml_pipeline(parameter: int):\n  ...\n# ZenMl merges the two configurations and uses the step configuration to override \n# values defined on the pipeline level\ntrain_model.configuration.settings[\"resources\"]\n# -> cpu_count: 2, gpu_count=1, memory=\"2GB\"\nsimple_ml_pipeline.configuration.settings[\"resources\"]\n# -> cpu_count: 2, memory=\"1GB\"\n```\n\n\n### \n\nCommon Setting Types\n\n#### \n\nResource Settings\n\nResource settings allow you to specify the CPU, memory, and GPU requirements for your steps.\n\nCopy```\nfrom zenml.config import ResourceSettings\n@step(settings={\"resources\": ResourceSettings(gpu_count=1, memory=\"2GB\")})\ndef train_model(data: dict) -> None:\n  ...\n@pipeline(settings={\"resources\": ResourceSettings(cpu_count=2, memory=\"1GB\")}) \ndef simple_ml_pipeline(parameter: int):\n  ...\n```\n\n\nWhen both pipeline and step resource settings are specified, they are merged with step settings taking precedence:\n\nCopy```\n# Result of merging the above configurations:\n# train_model.configuration.settings[\"resources\"]\n# -> cpu_count: 2, gpu_count=1, memory=\"2GB\"\n```\n\n\nNote that `ResourceSettings` are not always applied by all orchestrators. The ability to enforce resource constraints depends on the specific orchestrator being used. Some orchestrators like Kubernetes fully support these settings, while others may ignore them. In order to learn more, read the individual pages of the orchestrator you are using.\n\nResource settings also allow you to configure scaling options - including minimum and maximum number of instances, and scaling policy - for your pipeline deployments, when used at the pipeline level:\n\nCopy```\nfrom zenml.config import ResourceSettings\n@pipeline(settings={\"resources\": ResourceSettings(\n cpu_count=2,\n memory=\"4GB\",\n min_replicas=0,\n max_replicas=10,\n max_concurrency=10\n)}) \ndef simple_llm_pipeline(parameter: int):\n  ...\n```\n\n\nNote that `ResourceSettings` are not always applied exactly as specified by all deployers. Some deployers fully support these settings, while others may adjust them automatically to match a set of predefined static values or simply ignore them. In order to learn more, read the individual pages of the deployer you are using.\n\n#### \n\nDocker Settings\n\nDocker settings allow you to customize the containerization process:\n\nCopy```\n@pipeline(settings={\n  \"docker\": {\n    \"parent_image\": \"zenml-io/zenml-cuda:latest\"\n  }\n})\ndef my_pipeline():\n  ...\n```\n\n\nFor more detailed information on containerization options, see the containerization guide.\n\n#### \n\nDeployment Settings\n\nDeployment settings allow you to customize the web server and ASGI application used to run your pipeline deployments. You can specify a range of options, including custom endpoints, middleware, extensions and even custom files used to serve an entire single-page application alongside your pipeline:\n\nCopy```\nfrom typing import Dict, Any\nimport psutil\nfrom zenml.config import DeploymentSettings, EndpointSpec, EndpointMethod, SecureHeadersConfig\nfrom zenml import pipeline\nasync def health_detailed() -> Dict[str, Any]:\n  return {\n    \"status\": \"healthy\",\n    \"cpu_percent\": psutil.cpu_percent(),\n    \"memory_percent\": psutil.virtual_memory().percent,\n    \"disk_percent\": psutil.disk_usage(\"/\").percent,\n  }\n@pipeline(settings={\n  \"deployment\": DeploymentSettings(\n   custom_endpoints=[\n     EndpointSpec(\n       path=\"/health\",\n       method=EndpointMethod.GET,\n       handler=health_detailed,\n       auth_required=False,\n     ),\n   ],\n   secure_headers=SecureHeadersConfig(\n    csp=(\n      \"default-src 'none'; \"\n      \"script-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net; \"\n      \"connect-src 'self' https://cdn.jsdelivr.net; \"\n      \"style-src 'self' 'unsafe-inline'\"\n    ),\n   ),\n   dashboard_files_path=\"my/custom/ui\",\n})\ndef my_pipeline():\n  ...\n```\n\n\nFor more detailed information on deployment options, see the pipeline deployment guide, particularly the deployment settings section.\n\n### \n\nStack Component Configuration\n\n#### \n\nRegistration-time vs Runtime Stack Component Settings\n\nStack components have two types of configuration:\n\n  1. **Registration-time configuration** : Static settings defined when registering a component\n\nCopy```\n# Example: Setting a fixed tracking URL for MLflow\nzenml experiment-tracker register mlflow_tracker --flavor=mlflow --tracking_url=http://localhost:5000\n```\n\n\n  2. **Runtime settings** : Dynamic settings that can change between pipeline runs\n\nCopy```\n# Example: Setting experiment name that changes for each run\n@step(settings={\"experiment_tracker.mlflow\": {\"experiment_name\": \"custom_experiment\"}})\ndef my_step():\n  ...\n```\n\n\n\n\n\nEven for runtime settings, you can set default values during registration:\n\nCopy```\n# Setting a default value for \"nested\" setting\nzenml experiment-tracker register <n> --flavor=mlflow --nested=True\n```\n\n\n#### \n\nUsing the Right Key for Stack Component Settings\n\nWhen specifying stack-component-specific settings, the key follows this pattern:\n\nCopy```\n# Using just the component category\n@step(settings={\"step_operator\": {\"estimator_args\": {\"instance_type\": \"m7g.medium\"}}})\n# Or using the component category and flavor\n@step(settings={\"experiment_tracker.mlflow\": {\"experiment_name\": \"custom_experiment\"}})\n```\n\n\nIf you specify just the category (e.g., `step_operator`), ZenML applies these settings to whatever flavor of component is in your stack. If the settings don't apply to that flavor, they are ignored.\n\n### \n\nMaking Configurations Flexible with Environment Variables\n\nYou can make your configurations more flexible by referencing environment variables using the placeholder syntax `${ENV_VARIABLE_NAME}`:\n\n**In code:**\n\nCopy```\nfrom zenml import step\n@step(extra={\"value_from_environment\": \"${ENV_VAR}\"})\ndef my_step() -> None:\n  ...\n```\n\n\n**In configuration files:**\n\nCopy```\nextra:\n value_from_environment: ${ENV_VAR}\n combined_value: prefix_${ENV_VAR}_suffix\n```\n\n\nThis allows you to easily adapt your pipelines to different environments without changing code.\n\n### \n\nAutogenerate a template yaml file\n\nIf you want to generate a template yaml file of your specific pipeline, you can do so by using the `.write_run_configuration_template()` method. This will generate a yaml file with all options commented out. This way you can pick and choose the settings that are relevant to you.\n\nCopy```\nfrom zenml import pipeline\n...\n@pipeline(enable_cache=True) # set cache behavior at step level\ndef simple_ml_pipeline(parameter: int):\n  dataset = load_data(parameter=parameter)\n  train_model(dataset)\nsimple_ml_pipeline.write_run_configuration_template(path=\"<Insert_path_here>\")\n```\n\n\nAn example of a generated YAML configuration template\n\nCopy```\nbuild: Union[PipelineBuildBase, UUID, NoneType]\nenable_artifact_metadata: Optional[bool]\nenable_artifact_visualization: Optional[bool]\nenable_cache: Optional[bool]\nenable_step_logs: Optional[bool]\nextra: Mapping[str, Any]\nmodel:\n audience: Optional[str]\n description: Optional[str]\n ethics: Optional[str]\n license: Optional[str]\n limitations: Optional[str]\n name: str\n save_models_to_registry: bool\n suppress_class_validation_warnings: bool\n tags: Optional[List[str]]\n trade_offs: Optional[str]\n use_cases: Optional[str]\n version: Union[ModelStages, int, str, NoneType]\nparameters: Optional[Mapping[str, Any]]\nrun_name: Optional[str]\nschedule:\n catchup: bool\n cron_expression: Optional[str]\n end_time: Optional[datetime]\n interval_second: Optional[timedelta]\n name: Optional[str]\n run_once_start_time: Optional[datetime]\n start_time: Optional[datetime]\nsettings:\n docker:\n  apt_packages: List[str]\n  build_context_root: Optional[str]\n  build_options: Mapping[str, Any]\n  copy_files: bool\n  copy_global_config: bool\n  dockerfile: Optional[str]\n  dockerignore: Optional[str]\n  environment: Mapping[str, Any]\n  runtime_environment: Mapping[str, Any]\n  install_stack_requirements: bool\n  parent_image: Optional[str]\n  python_package_installer: PythonPackageInstaller\n  replicate_local_python_environment: Union[List[str], PythonEnvironmentExportMethod,\n   NoneType]\n  required_integrations: List[str]\n  requirements: Union[NoneType, str, List[str]]\n  skip_build: bool\n  prevent_build_reuse: bool\n  allow_including_files_in_images: bool\n  allow_download_from_code_repository: bool\n  allow_download_from_artifact_store: bool\n  target_repository: str\n  user: Optional[str]\n resources:\n  cpu_count: Optional[PositiveFloat]\n  gpu_count: Optional[NonNegativeInt]\n  memory: Optional[ConstrainedStrValue]\n  deployment:\n   api_url_path: str\n   app_description: Union[str, NoneType]\n   app_extensions: Union[List[AppExtensionSpec], NoneType]\n   app_kwargs: Dict[str, Any]\n   app_title: Union[str, NoneType]\n   app_version: Union[str, NoneType]\n   cors:\n    allow_credentials: bool\n    allow_headers: List[str]\n    allow_methods: List[str]\n    allow_origins: List[str]\n   custom_endpoints: Union[List[EndpointSpec], NoneType]\n   custom_middlewares: Union[List[MiddlewareSpec], NoneType]\n   dashboard_files_path: Union[str, NoneType]\n   deployment_app_runner_flavor: Union[Annotated[SourceOrObject, BeforeValidator,\n    PlainSerializer], NoneType]\n   deployment_app_runner_kwargs: Dict[str, Any]\n   deployment_service_class: Union[Annotated[SourceOrObject, BeforeValidator, PlainSerializer],\n    NoneType]\n   deployment_service_kwargs: Dict[str, Any]\n   docs_url_path: str\n   health_url_path: str\n   include_default_endpoints: bool\n   include_default_middleware: bool\n   info_url_path: str\n   invoke_url_path: str\n   log_level: LoggingLevels\n   metrics_url_path: str\n   redoc_url_path: str\n   root_url_path: str\n   secure_headers:\n    cache: Union[bool, str]\n    content: Union[bool, str]\n    csp: Union[bool, str]\n    hsts: Union[bool, str]\n    permissions: Union[bool, str]\n    referrer: Union[bool, str]\n    server: Union[bool, str]\n    xfo: Union[bool, str]\n   shutdown_hook: Union[Annotated[SourceOrObject, BeforeValidator, PlainSerializer],\n    NoneType]\n   shutdown_hook_kwargs: Dict[str, Any]\n   startup_hook: Union[Annotated[SourceOrObject, BeforeValidator, PlainSerializer],\n    NoneType]\n   startup_hook_kwargs: Dict[str, Any]\n   thread_pool_size: int\n   uvicorn_host: str\n   uvicorn_kwargs: Dict[str, Any]\n   uvicorn_port: int\n   uvicorn_workers: int\nsteps:\n load_data:\n  enable_artifact_metadata: Optional[bool]\n  enable_artifact_visualization: Optional[bool]\n  enable_cache: Optional[bool]\n  enable_step_logs: Optional[bool]\n  experiment_tracker: Optional[str]\n  extra: Mapping[str, Any]\n  failure_hook_source:\n   attribute: Optional[str]\n   module: str\n   type: SourceType\n  model:\n   audience: Optional[str]\n   description: Optional[str]\n   ethics: Optional[str]\n   license: Optional[str]\n   limitations: Optional[str]\n   name: str\n   save_models_to_registry: bool\n   suppress_class_validation_warnings: bool\n   tags: Optional[List[str]]\n   trade_offs: Optional[str]\n   use_cases: Optional[str]\n   version: Union[ModelStages, int, str, NoneType]\n  name: Optional[str]\n  outputs:\n   output:\n    default_materializer_source:\n     attribute: Optional[str]\n     module: str\n     type: SourceType\n   materializer_source: Optional[Tuple[Source, ...]]\n  parameters: {}\n  settings:\n   docker:\n    apt_packages: List[str]\n    build_context_root: Optional[str]\n    build_options: Mapping[str, Any]\n    copy_files: bool\n    copy_global_config: bool\n    dockerfile: Optional[str]\n    dockerignore: Optional[str]\n    environment: Mapping[str, Any]\n    runtime_environment: Mapping[str, Any]\n    install_stack_requirements: bool\n    parent_image: Optional[str]\n    python_package_installer: PythonPackageInstaller\n    replicate_local_python_environment: Union[List[str], PythonEnvironmentExportMethod,\n     NoneType]\n    required_integrations: List[str]\n    requirements: Union[NoneType, str, List[str]]\n    skip_build: bool\n    prevent_build_reuse: bool\n    allow_including_files_in_images: bool\n    allow_download_from_code_repository: bool\n    allow_download_from_artifact_store: bool\n    target_repository: str\n    user: Optional[str]\n   resources:\n    cpu_count: Optional[PositiveFloat]\n    gpu_count: Optional[NonNegativeInt]\n    memory: Optional[ConstrainedStrValue]\n  step_operator: Optional[str]\n  success_hook_source:\n   attribute: Optional[str]\n   module: str\n   type: SourceType\n train_model:\n  enable_artifact_metadata: Optional[bool]\n  enable_artifact_visualization: Optional[bool]\n  enable_cache: Optional[bool]\n  enable_step_logs: Optional[bool]\n  experiment_tracker: Optional[str]\n  extra: Mapping[str, Any]\n  failure_hook_source:\n   attribute: Optional[str]\n   module: str\n   type: SourceType\n  model:\n   audience: Optional[str]\n   description: Optional[str]\n   ethics: Optional[str]\n   license: Optional[str]\n   limitations: Optional[str]\n   name: str\n   save_models_to_registry: bool\n   suppress_class_validation_warnings: bool\n   tags: Optional[List[str]]\n   trade_offs: Optional[str]\n   use_cases: Optional[str]\n   version: Union[ModelStages, int, str, NoneType]\n  name: Optional[str]\n  outputs: {}\n  parameters: {}\n  settings:\n   docker:\n    apt_packages: List[str]\n    build_context_root: Optional[str]\n    build_options: Mapping[str, Any]\n    copy_files: bool\n    copy_global_config: bool\n    dockerfile: Optional[str]\n    dockerignore: Optional[str]\n    environment: Mapping[str, Any]\n    runtime_environment: Mapping[str, Any]\n    install_stack_requirements: bool\n    parent_image: Optional[str]\n    python_package_installer: PythonPackageInstaller\n    replicate_local_python_environment: Union[List[str], PythonEnvironmentExportMethod,\n     NoneType]\n    required_integrations: List[str]\n    requirements: Union[NoneType, str, List[str]]\n    skip_build: bool\n    prevent_build_reuse: bool\n    allow_including_files_in_images: bool\n    allow_download_from_code_repository: bool\n    allow_download_from_artifact_store: bool\n    target_repository: str\n    user: Optional[str]\n   resources:\n    cpu_count: Optional[PositiveFloat]\n    gpu_count: Optional[NonNegativeInt]\n    memory: Optional[ConstrainedStrValue]\n  step_operator: Optional[str]\n  success_hook_source:\n   attribute: Optional[str]\n   module: str\n   type: SourceType\n\n```\n\n\nWhen you want to configure your pipeline with a certain stack in mind, you can do so as well: `...write_run_configuration_template(stack=<Insert_stack_here>)`\n\nPreviousSteps & PipelinesNextScheduling\n\nLast updated 1 month ago\n\nWas this helpful?\n",
    "summary": "## TL;DR Summary of ZenML Configuration Documentation\n\n### Configuration Overview\nZenML allows flexible configuration of pipelines and steps using two primary methods:\n- **`.configure()`**: Modifies configuration in-place.\n- **`.with_options()`**: Creates a new configuration copy.\n\n### Approaches to Configuration\n- **Pipeline Configuration**: Use `.configure()` to set pipeline-wide settings.\n- **Runtime Configuration**: Use `.with_options()` for step-specific parameters or YAML files.\n- **Step-Level Configuration**: Use the `@step` decorator for individual step settings.\n\n### Types of Settings\n1. **General Settings**: Applicable to all pipelines (e.g., Docker, Resource, Deployment settings).\n2. **Stack-Component-Specific Settings**: Configurations for specific components in the stack.\n\n### Configuration Hierarchy\n- Code configurations override YAML settings.\n- Step-level settings override pipeline-level settings.\n\n### Environment Variables\nConfigurations can reference environment variables for flexibility.\n\n### Autogenerate YAML Template\nUse `.write_run_configuration_template()` to create a YAML template for pipeline settings.",
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/scheduling",
        "https://docs.zenml.io/concepts/steps_and_pipelines/logging",
        "https://docs.zenml.io/concepts/steps_and_pipelines/yaml_configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/sources",
        "https://docs.zenml.io/concepts/steps_and_pipelines/advanced_features",
        "https://docs.zenml.io/concepts/steps_and_pipelines/dynamic_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#approaches-to-configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#types-of-settings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#configuration-hierarchy",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#common-setting-types",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#stack-component-configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#making-configurations-flexible-with-environment-variables",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#autogenerate-a-template-yaml-file",
        "https://docs.zenml.io/concepts",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#understanding-.configure-vs-.with_options",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#pipeline-configuration-with-configure",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#runtime-configuration-with-with_options",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#step-level-configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#direct-component-assignment",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#resource-settings",
        "https://docs.zenml.io/stacks/stack-components/orchestrators",
        "https://docs.zenml.io/stacks/stack-components/deployers",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#docker-settings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#deployment-settings",
        "https://docs.zenml.io/concepts/deployment/deployment_settings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#registration-time-vs-runtime-stack-component-settings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#using-the-right-key-for-stack-component-settings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration#an-example-of-a-generated-yaml-configuration-template",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=5aBlTJNbVDkrxJp7J1J9"
    ]
}