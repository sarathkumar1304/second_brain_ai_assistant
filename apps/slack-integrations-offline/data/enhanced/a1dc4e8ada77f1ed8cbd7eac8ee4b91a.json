{
    "id": "a1dc4e8ada77f1ed8cbd7eac8ee4b91a",
    "metadata": {
        "id": "a1dc4e8ada77f1ed8cbd7eac8ee4b91a",
        "url": "https://docs.zenml.io/concepts/containerization",
        "title": "Containerization | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Customize Docker builds to run your pipelines in isolated, well-defined environments.",
            "keywords": null,
            "author": null,
            "og:title": "Containerization | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Customize Docker builds to run your pipelines in isolated, well-defined environments.",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/HrpS8YZG0eqgfwGoW1Eh",
            "twitter:card": "summary_large_image",
            "twitter:title": "Containerization | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Customize Docker builds to run your pipelines in isolated, well-defined environments.",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/HrpS8YZG0eqgfwGoW1Eh"
        }
    },
    "content": "`Ctrl``k`\n\nGitBook AssistantAsk\n\nProductResourcesGitHubStart free\n\nMore\n\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\n\nGitBook Assistant\n\nGitBook Assistant\n\nWorking...Thinking...\n\nGitBook Assistant\n\n##### Good evening\n\nI'm here to help you with the docs.\n\nWhat is this page about?What should I read next?Can you give an example?\n\n`Ctrl``i`\n\nAI Based on your context\n\nSend\n\n  * Getting Started\n\n    * Welcome to ZenML\n    * Installation\n    * Hello World\n    * Your First AI Pipeline\n    * Core Concepts\n    * System Architecture\n  * Deploying ZenML\n\n    * Deploy\n    * Connect\n    * Manage\n  * Concepts\n\n    * Steps & Pipelines\n    * Artifacts\n    * Stack & Components\n    * Service Connectors\n    * Pipeline Snapshots\n    * Pipeline Deployments\n    * Containerization\n    * Code Repositories\n    * Secrets\n    * Environment Variables\n    * Tags\n    * Metadata\n    * Models\n    * Dashboard\n    * Templates\n  * Reference\n\n    * Community & content\n    * Environment Variables\n    * MCP Docs & llms.txt\n    * FAQ\n    * Global settings\n    * Legacy docs\n\n\n\nPowered by GitBook\n\nOn this page\n\n  * Understanding Docker Builds in ZenML\n  * Docker Build Process\n  * Requirements Installation Order\n  * Configuring Docker Settings\n  * Pipeline-Level Settings\n  * Step-Level Settings\n  * Using YAML Configuration\n  * Specifying Docker Build Options\n  * Using Custom Parent Images\n  * Pre-built Parent Images\n  * Skip Build Process\n  * Custom Dockerfiles\n  * Managing Dependencies\n  * Python Dependencies\n  * System Packages\n  * Installation Control\n  * Private PyPI Repositories\n  * Source Code Management\n  * Controlling Included Files\n  * Environment Variables\n  * Build Reuse and Optimization\n  * What is a Pipeline Build?\n  * Reusing Builds\n  * Controlling Image Repository Names\n  * Specifying Image tags\n  * Decoupling Code from Builds\n  * Image Build Location\n  * Container User Permissions\n  * Best Practices\n\n\n\nWas this helpful?\n\nGitBook AssistantAsk\n\n  1. Concepts\n\n\n\n# Containerization\n\nCustomize Docker builds to run your pipelines in isolated, well-defined environments.\n\nZenML executes pipeline steps sequentially in the active Python environment when running locally. However, with remote orchestrators or step operators, ZenML builds Docker images to run your pipeline in an isolated, well-defined environment.\n\nThis page explains how ZenML's Docker build process works and how you can customize it to meet your specific requirements.\n\n## \n\nUnderstanding Docker Builds in ZenML\n\nWhen a pipeline is run with a remote orchestrator, a Dockerfile is dynamically generated at runtime. It is then used to build the Docker image using the image builder component of your stack. The Dockerfile consists of the following steps:\n\n  1. **Starts from a parent image** that has ZenML installed. By default, this will use the official ZenML image for the Python and ZenML version that you're using in the active Python environment.\n\n  2. **Installs additional pip dependencies**. ZenML automatically detects which integrations are used in your stack and installs the required dependencies.\n\n  3. **Optionally copies your source files**. Your source files need to be available inside the Docker container so ZenML can execute your step code.\n\n  4. **Sets user-defined environment variables.**\n\n\n\n\nThe process described above is automated by ZenML and covers most basic use cases. This page covers various ways to customize the Docker build process to fit your specific needs.\n\n### \n\nDocker Build Process\n\nZenML uses the following process to decide how to build Docker images:\n\n  * **No**`**dockerfile**`**specified** : If any of the options regarding requirements, environment variables, or copying files require us to build an image, ZenML will build this image. Otherwise, the `parent_image` will be used to run the pipeline.\n\n  * `**dockerfile**`**specified** : ZenML will first build an image based on the specified Dockerfile. If any additional options regarding requirements, environment variables, or copying files require an image built on top of that, ZenML will build a second image. If not, the image built from the specified Dockerfile will be used to run the pipeline.\n\n\n\n\n### \n\nRequirements Installation Order\n\nDepending on the configuration of your Docker settings, requirements will be installed in the following order (each step is optional):\n\n  1. The packages installed in your local Python environment (if enabled)\n\n  2. The packages required by the stack (unless disabled by setting `install_stack_requirements=False`)\n\n  3. The packages specified via the `required_integrations`\n\n  4. The packages specified via the `requirements` attribute\n\n\n\n\nFor a full list of configuration options, check out the DockerSettings object on the SDKDocs.\n\n## \n\nConfiguring Docker Settings\n\nYou can customize Docker builds for your pipelines and steps using the `DockerSettings` class:\n\nCopy```\nfrom zenml.config import DockerSettings\n```\n\n\nThere are multiple ways to supply these settings:\n\n### \n\nPipeline-Level Settings\n\nConfiguring settings on a pipeline applies them to all steps of that pipeline:\n\nCopy```\nfrom zenml import pipeline, step\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings()\n@step\ndef my_step() -> None:\n  \"\"\"Example step.\"\"\"\n  pass\n# Either add it to the decorator\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline() -> None:\n  my_step()\n# Or configure the pipelines options\nmy_pipeline = my_pipeline.with_options(\n  settings={\"docker\": docker_settings}\n)\n```\n\n\n### \n\nStep-Level Settings\n\nFor more fine-grained control, configure settings on individual steps. This is particularly useful when different steps have conflicting requirements or when some steps need specialized environments:\n\nCopy```\nfrom zenml import step\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings()\n# Either add it to the decorator\n@step(settings={\"docker\": docker_settings})\ndef my_step() -> None:\n  pass\n# Or configure the step options\nmy_step = my_step.with_options(\n  settings={\"docker\": docker_settings}\n)\n```\n\n\n### \n\nUsing YAML Configuration\n\nDefine settings in a YAML configuration file for better separation of code and configuration:\n\nCopy```\nsettings:\n  docker:\n    parent_image: python:3.11-slim\n    apt_packages:\n     - git\n     - curl\n    requirements:\n     - tensorflow==2.8.0\n     - pandas\nsteps:\n training_step:\n  settings:\n    docker:\n      parent_image: pytorch/pytorch:2.2.0-cuda11.8-cudnn8-runtime\n      required_integrations:\n       - wandb\n       - mlflow\n```\n\n\nCheck out this page for more information on the hierarchy and precedence of the various ways in which you can supply the settings.\n\n### \n\nSpecifying Docker Build Options\n\nYou can customize the build process by specifying build options that get passed to the build method of the image builder:\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(\n  build_config={\"build_options\": {\"buildargs\": {\"MY_ARG\": \"value\"}}}\n)\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nFor the default local image builder, these options are passed to the `docker build` command.\n\nIf you're running your pipelines on MacOS with ARM architecture, the local Docker caching does not work unless you specify the target platform of the image:\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(\n  build_config={\"build_options\": {\"platform\": \"linux/amd64\"}}\n)\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\n## \n\nUsing Custom Parent Images\n\n### \n\nPre-built Parent Images\n\nTo use a static parent image (e.g., with internal dependencies pre-installed):\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(parent_image=\"my_registry.io/image_name:tag\")\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nZenML will use this image as the base and still perform the following steps:\n\n  1. Install additional pip dependencies\n\n  2. Copy source files (if configured)\n\n  3. Set environment variables\n\n\n\n\nIf you're going to use a custom parent image, you need to make sure that it has Python, pip, and ZenML installed for it to work. If you need a starting point, you can take a look at the Dockerfile that ZenML uses here.\n\n### \n\nSkip Build Process\n\nTo use the image directly to run your steps without including any code or installing any requirements on top of it, skip the Docker builds by setting `skip_build=True`:\n\nCopy```\ndocker_settings = DockerSettings(\n  parent_image=\"my_registry.io/image_name:tag\",\n  skip_build=True\n)\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nWhen `skip_build` is enabled, the `parent_image` will be used directly to run the steps of your pipeline without any additional Docker builds on top of it. This means that **none** of the following will happen:\n\n  * No installation of local Python environment packages\n\n  * No installation of stack requirements\n\n  * No installation of required integrations\n\n  * No installation of specified requirements\n\n  * No installation of apt packages\n\n  * No inclusion of source files in the container\n\n  * No setting of environment variables\n\n\n\n\nThis is an advanced feature and may cause unintended behavior when running your pipelines. If you use this, ensure your image contains everything necessary to run your pipeline:\n\n  1. Your stack requirements\n\n  2. Integration requirements\n\n  3. Project-specific requirements\n\n  4. Any system packages\n\n  5. Your project code files (unless a code repository is registered or `allow_download_from_artifact_store` is enabled)\n\n\n\n\nMake sure that Python, `pip` and `zenml` are installed in your image, and that your code is in the `/app` directory set as the active working directory.\n\nAlso note that the Docker settings validator will raise an error if you set `skip_build=True` without specifying a `parent_image`. A parent image is required when skipping the build as it will be used directly to run your pipeline steps.\n\n### \n\nCustom Dockerfiles\n\nFor greater control, you can specify a custom Dockerfile and build context:\n\nCopy```\ndocker_settings = DockerSettings(\n  dockerfile=\"/path/to/dockerfile\",\n  build_context_root=\"/path/to/build/context\",\n  parent_image_build_config={\n    \"build_options\": {\"buildargs\": {\"MY_ARG\": \"value\"}},\n    \"dockerignore\": \"/path/to/.dockerignore\"\n  }\n)\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nHere is how the build process looks like with a custom Dockerfile:\n\n  * `**Dockerfile**`**specified** : ZenML will first build an image based on the specified `Dockerfile`. If any options regarding requirements, environment variables, or copying files require an additional image built on top of that, ZenML will build a second image. Otherwise, the image built from the specified `Dockerfile` will be used to run the pipeline.\n\n\n\n\nImportant notes about using a custom Dockerfile:\n\n  * When you specify a custom `dockerfile`, the `parent_image` attribute will be ignored\n\n  * The image built from your Dockerfile must have ZenML installed\n\n  * If you set `build_context_root`, that directory will be used as the build context for the Docker build. If left empty, the build context will only contain the Dockerfile\n\n  * You can configure the build options by setting `parent_image_build_config` with specific build options and dockerignore settings\n\n\n\n\n## \n\nManaging Dependencies\n\nZenML offers several ways to specify dependencies for your Docker containers:\n\n### \n\nPython Dependencies\n\nBy default, ZenML automatically installs all packages required by your active ZenML stack.\n\nIn future versions, if none of the `replicate_local_python_environment`, `pyproject_path` or `requirements` attributes on `DockerSettings` are specified, ZenML will try to automatically find a `requirements.txt` and `pyproject.toml` files inside your current source root and install packages from the first one it finds. You can disable this behavior by setting `disable_automatic_requirements_detection=True`. If you already want this automatic detection in current versions of ZenML, set `disable_automatic_requirements_detection=False`.\n\n  1. **Replicate Local Environment** :\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(replicate_local_python_environment=True)\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nThis will run `pip freeze` to get a list of the installed packages in your local Python environment and will install them in the Docker image. This ensures that the same exact dependencies will be installed. {% hint style=\"warning\" %} This does not work when you have a local project installed. To install local projects, check out the `Install Local Projects` section below. {% endhint %}\n\n  2. **Specify a**`**pyproject.toml**`**file** :\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(pyproject_path=\"/path/to/pyproject.toml\")\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\nBy default, ZenML will try to export the dependencies specified in the `pyproject.toml` by trying to run `uv export` and `poetry export`. If both of these commands do not work for your `pyproject.toml` file or you want to customize the command (for example to install certain extras), you can specify a custom command using the `pyproject_export_command` attribute. This command must output a list of requirements following the format of the requirements file. The command can contain a `{directory}` placeholder which will be replaced with the directory in which the `pyproject.toml` file is stored.\n\nCopy```\nfrom zenml import pipeline\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(pyproject_export_command=[\n  \"uv\",\n  \"export\",\n  \"--extra=train\",\n  \"--format=requirements-txt\",\n  \"--directory={directory}\"\n])\n@pipeline(settings={\"docker\": docker_settings})\ndef my_pipeline(...):\n  ...\n```\n\n\n  3. **Specify Requirements Directly** :\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(requirements=[\"torch==1.12.0\", \"torchvision\"])\n```\n\n\n  4. **Use Requirements File** :\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(requirements=\"/path/to/requirements.txt\")\n```\n\n\n  5. **Specify ZenML Integrations** :\n\nCopy```\nfrom zenml.integrations.constants import PYTORCH, EVIDENTLY\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(required_integrations=[PYTORCH, EVIDENTLY])\n```\n\n\n  6. **Control Stack Requirements** : By default, ZenML installs the requirements needed by your active stack. You can disable this behavior if needed:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(install_stack_requirements=False)\n```\n\n\n  7. **Control Deployment Requirements** : By default, if you have a Deployer stack component in your active stack, ZenML installs the requirements needed by the deployment application configured in your deployment settings. You can disable this behavior if needed:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(install_deployment_requirements=False)\n```\n\n\n  8. **Install Local Projects** : If your code requires the installation of some local code files as a python package, you can specify a command that installs it as follows:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(local_project_install_command=\"pip install . --no-deps\")\n```\n\n\n{% hint style=\"warning\" %} Installing a local python package only works if your code files are included in the Docker image, so make sure you have `allow_including_files_in_images=True` in your Docker settings. If you want to instead use the code download functionality to avoid building new Docker images for each pipeline run, you can follow this example. {% endhint %}\n\n\n\n\nDepending on the options specified in your Docker settings, ZenML installs the requirements in the following order (each step optional):\n\n  1. The packages installed in your local Python environment\n\n  2. The packages required by the stack (unless disabled by setting `install_stack_requirements=False`)\n\n  3. The packages specified via the `required_integrations`\n\n  4. The packages defined in the pyproject.toml file specified by the `pyproject_path` attribute\n\n  5. The packages specified via the `requirements` attribute\n\n\n\n\n### \n\nSystem Packages\n\nSpecify apt packages to be installed in the Docker image:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(apt_packages=[\"git\", \"curl\", \"libsm6\", \"libxext6\"])\n```\n\n\n### \n\nInstallation Control\n\nControl how packages are installed:\n\nCopy```\n# Use custom installer arguments\ndocker_settings = DockerSettings(python_package_installer_args={\"timeout\": 1000})\n# Use pip instead of uv\nfrom zenml.config import DockerSettings, PythonPackageInstaller\ndocker_settings = DockerSettings(python_package_installer=PythonPackageInstaller.PIP)\n# Or as a string\ndocker_settings = DockerSettings(python_package_installer=\"pip\")\n# Use uv (default)\ndocker_settings = DockerSettings(python_package_installer=PythonPackageInstaller.UV)\n```\n\n\nThe available package installers are:\n\n  * `uv`: The default python package installer\n\n  * `pip`: An alternative python package installer\n\n\n\n\nFull documentation for how `uv` works with PyTorch can be found on the Astral Docs website here. It covers some of the particular gotchas and details you might need to know.\n\n## \n\nPrivate PyPI Repositories\n\nFor packages that require authentication from private repositories:\n\nCopy```\nimport os\ndocker_settings = DockerSettings(\n  requirements=[\"my-internal-package==0.1.0\"],\n  environment={\n    'PIP_EXTRA_INDEX_URL': f\"https://{os.environ.get('PYPI_TOKEN', '')}@my-private-pypi-server.com/{os.environ.get('PYPI_USERNAME', '')}/\"}\n)\n```\n\n\nBe cautious with handling credentials. Always use secure methods to manage and distribute authentication information within your team. Consider using secrets management tools or environment variables passed securely.\n\n## \n\nSource Code Management\n\nYou can specify how the files inside your source root directory are handled for containerized steps:\n\nCopy```\ndocker_settings = DockerSettings(\n  # Download files from code repository if available\n  allow_download_from_code_repository=True,\n  # If no code repository, upload code to artifact store\n  allow_download_from_artifact_store=True,\n  # If neither of the above, include files in the image\n  allow_including_files_in_images=True\n)\n```\n\n\nZenML handles your source code in the following order:\n\n  1. If `allow_download_from_code_repository` is `True` and your files are inside a registered code repository and the repository has no local changes, the files will be downloaded from the code repository and not included in the image.\n\n  2. If the previous option is disabled or no code repository without local changes exists for the root directory, ZenML will archive and upload your code to the artifact store if `allow_download_from_artifact_store` is `True`.\n\n  3. If both previous options were disabled or not possible, ZenML will include your files in the Docker image if `allow_including_files_in_images` is enabled. This means a new Docker image has to be built each time you modify one of your code files.\n\n\n\n\nSetting all of the above attributes to `False` is not recommended and will most likely cause unintended and unanticipated behavior when running your pipelines. If you do this, you're responsible that all your files are at the correct paths in the Docker images that will be used to run your pipeline steps.\n\n### \n\nControlling Included Files\n\n  * When downloading files from a code repository, use a `.gitignore` file to exclude files.\n\n  * When including files in the image, use a `.dockerignore` file to exclude files and keep the image smaller:\n\nCopy```\n# Have a file called .dockerignore in your source root directory\n# Or explicitly specify a .dockerignore file to use:\ndocker_settings = DockerSettings(build_config={\"dockerignore\": \"/path/to/.dockerignore\"})\n```\n\n\n\n\n\n## \n\nEnvironment Variables\n\nYou can configure two types of environment variables:\n\n  1. Environment variables that will be set in the beginning of the Docker image building process before any python or apt packages are installed:\n\n\n\n\nCopy```\ndocker_settings = DockerSettings(\n  environment={\n    \"PYTHONUNBUFFERED\": \"1\",\n    \"MODEL_DIR\": \"/models\",\n    \"API_KEY\": \"${GLOBAL_API_KEY}\" # Reference a local environment variable\n  }\n)\n```\n\n\n  1. Environment variables that will be set at the end of the Docker image building process after the python and apt packages are installed, right before the container entrypoint (useful for setting proxy environment variables for example):\n\n\n\n\nCopy```\ndocker_settings = DockerSettings(\n  runtime_environment={\n    \"HTTP_PROXY\": \"http://proxy.example.com:8080\",\n    \"HTTPS_PROXY\": \"http://proxy.example.com:8080\",\n    \"NO_PROXY\": \"localhost,127.0.0.1\"\n  }\n)\n```\n\n\nEnvironment variables can reference other environment variables set in your client environment by using the `${VAR_NAME}` syntax. ZenML will substitute these before building the images.\n\n## \n\nBuild Reuse and Optimization\n\nZenML automatically reuses Docker builds when possible to save time and resources:\n\n### \n\nWhat is a Pipeline Build?\n\nA pipeline build is an encapsulation of a pipeline and the stack it was run on. It contains the Docker images that were built for the pipeline with all required dependencies from the stack, integrations and the user. Optionally, it also contains the pipeline code.\n\nList all available builds for a pipeline:\n\nCopy```\nzenml pipeline builds list --pipeline_id='startswith:ab53ca'\n```\n\n\nCreate a build manually (useful for pre-building images):\n\nCopy```\nzenml pipeline build --stack vertex-stack my_module.my_pipeline_instance\n```\n\n\nYou can use options to specify the configuration file and the stack to use for the build. Learn more about the build function here.\n\n### \n\nReusing Builds\n\nBy default, when you run a pipeline, ZenML will check if a build with the same pipeline and stack exists. If it does, it will reuse that build automatically. However, you can also force using a specific build by providing its ID:\n\nCopy```\npipeline_instance.run(build=\"<build_id>\")\n```\n\n\nYou can also specify this in configuration files:\n\nCopy```\nbuild: your-build-id-here\n```\n\n\nSpecifying a custom build when running a pipeline will **not run the code on your client machine** but will use the code **included in the Docker images of the build**. Even if you make local code changes, reusing a build will _always_ execute the code bundled in the Docker image, rather than the local code.\n\n### \n\nControlling Image Repository Names\n\nYou can control where your Docker image is pushed by specifying a target repository name:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(target_repository=\"my-custom-repo-name\")\n```\n\n\nThe repository name will be appended to the registry URI of your container registry stack component. For example, if your container registry URI is `gcr.io/my-project` and you set `target_repository=\"zenml-pipelines\"`, the full image name would be `gcr.io/my-project/zenml-pipelines`.\n\nIf you don't specify a target repository, the default repository name configured in your container registry stack component settings will be used.\n\n### \n\nSpecifying Image tags\n\nYou can control the tag of the generated Docker images using the image tag option:\n\nCopy```\nfrom zenml.config import DockerSettings\ndocker_settings = DockerSettings(image_tag=\"1.0.0\")\n```\n\n\nKeep in mind that this will be applied to all images built using the DockerSettings object. If there are multiple such images, only one of them will keep the tag while the rest will be untagged.\n\n### \n\nDecoupling Code from Builds\n\nTo reuse Docker builds while still using your latest code changes, you need to decouple your code from the build. There are two main approaches:\n\n#### \n\n1. Using the Artifact Store to Upload Code\n\nYou can let ZenML use the artifact store to upload your code. This is the default behavior if no code repository is detected and the `allow_download_from_artifact_store` flag is not set to `False` in your `DockerSettings`.\n\n#### \n\n2. Using Code Repositories for Faster Builds\n\nRegistering a code repository lets you avoid building images each time you run a pipeline **and** quickly iterate on your code. When running a pipeline that is part of a local code repository checkout, ZenML can instead build the Docker images without including any of your source files, and download the files inside the container before running your code.\n\nZenML will **automatically figure out which builds match your pipeline and reuse the appropriate build id**. Therefore, you **do not** need to explicitly pass in the build id when you have a clean repository state and a connected git repository.\n\nIn order to benefit from the advantages of having a code repository in a project, you need to make sure that **the relevant integrations are installed for your ZenML installation.**. For instance, let's assume you are working on a project with ZenML and one of your team members has already registered a corresponding code repository of type `github` for it. If you do `zenml code-repository list`, you would also be able to see this repository. However, in order to fully use this repository, you still need to install the corresponding integration for it, in this example the `github` integration.\n\nCopy```\nzenml integration install github\n```\n\n\n#### \n\nDetecting local code repository checkouts\n\nOnce you have registered one or more code repositories, ZenML will check whether the files you use when running a pipeline are tracked inside one of those code repositories. This happens as follows:\n\n  * First, the source root is computed\n\n  * Next, ZenML checks whether this source root directory is included in a local checkout of one of the registered code repositories\n\n\n\n\n#### \n\nTracking code versions for pipeline runs\n\nIf a local code repository checkout is detected when running a pipeline, ZenML will store a reference to the current commit for the pipeline run, so you'll be able to know exactly which code was used.\n\nNote that this reference is only tracked if your local checkout is clean (i.e. it does not contain any untracked or uncommitted files). This is to ensure that your pipeline is actually running with the exact code stored at the specific code repository commit.\n\nIf you want to ignore untracked files, you can set the `ZENML_CODE_REPOSITORY_IGNORE_UNTRACKED_FILES` environment variable to `True`. When doing this, you're responsible that the files committed to the repository includes everything necessary to run your pipeline.\n\n#### \n\nPreventing Build Reuse\n\nThere might be cases where you want to force a new build, even if a suitable existing build is available. You can do this by setting `prevent_build_reuse=True`:\n\nCopy```\ndocker_settings = DockerSettings(prevent_build_reuse=True)\n```\n\n\nThis is useful in scenarios like:\n\n  * When you've made changes to your image building process that aren't tracked by ZenML\n\n  * When troubleshooting issues in your Docker image\n\n  * When you want to ensure your Docker image uses the most up-to-date base images\n\n\n\n\n#### \n\nTips and Best Practices for Build Reuse\n\n  * **Clean Repository State** : The file download is only possible if the local checkout is clean (no untracked or uncommitted files) and the latest commit has been pushed to the remote repository.\n\n  * **Configuration Options** : If you want to disable or enforce downloading of files, check the DockerSettings for available options.\n\n  * **Team Collaboration** : Using code repositories allows team members to reuse images that colleagues might have built for the same stack, enhancing collaboration efficiency.\n\n  * **Build Selection** : ZenML automatically selects matching builds, but you can override this with explicit build IDs for special cases.\n\n\n\n\n## \n\nImage Build Location\n\nBy default, execution environments are created locally using the local Docker client. However, this requires Docker installation and permissions. ZenML offers image builders, a special stack component, allowing users to build and push Docker images in a different specialized _image builder environment_.\n\nNote that even if you don't configure an image builder in your stack, ZenML still uses the local image builder to retain consistency across all builds. In this case, the image builder environment is the same as the client environment.\n\nYou don't need to directly interact with any image builder in your code. As long as the image builder that you want to use is part of your active ZenML stack, it will be used automatically by any component that needs to build container images.\n\n## \n\nContainer User Permissions\n\nBy default, Docker containers often run as the `root` user, which can pose security risks. ZenML allows you to specify a different user to run your containers:\n\nCopy```\ndocker_settings = DockerSettings(user=\"non-root-user\")\n```\n\n\nWhen you set the `user` parameter:\n\n  * The specified user will become the owner of the `/app` directory, which contains all your code\n\n  * The container entrypoint will run as this user instead of root\n\n  * This can help improve security by following the principle of least privilege\n\n\n\n\n## \n\nBest Practices\n\n  1. **Use code repositories** to speed up builds and enable team collaboration. This approach is highly recommended for production environments.\n\n  2. **Keep dependencies minimal** to reduce build times. Only include packages you actually need.\n\n  3. **Use fine-grained Docker settings** at the step level for conflicting requirements. This prevents dependency conflicts and reduces image sizes.\n\n  4. **Use pre-built images** for common environments. This can significantly speed up your workflow.\n\n  5. **Configure dockerignore files** to reduce image size. Large Docker images take longer to build, push, and pull.\n\n  6. **Leverage build caching** by structuring your Dockerfiles and build processes to maximize cache hits.\n\n  7. **Use environment variables** for configuration instead of hardcoding values in your images.\n\n  8. **Test your Docker builds locally** before using them in production pipelines.\n\n  9. **Keep your repository clean** (no uncommitted changes) when running pipelines to ensure ZenML can correctly track code versions.\n\n  10. **Use metadata and labels** to help identify and manage your Docker images.\n\n  11. **Run containers as non-root users** when possible to improve security.\n\n\n\n\nBy following these practices, you can optimize your Docker builds in ZenML and create a more efficient workflow.\n\nPreviousDeployment SettingsNextCode Repositories\n\nLast updated 24 days ago\n\nWas this helpful?\n",
    "summary": "## TL;DR Summary of ZenML Docker Builds Documentation\n\n### Understanding Docker Builds in ZenML\n- ZenML builds Docker images for pipelines using a dynamically generated Dockerfile.\n- The build process includes starting from a parent image, installing dependencies, copying source files, and setting environment variables.\n\n### Docker Build Process\n- If no Dockerfile is specified, ZenML uses the parent image. If specified, it builds from that Dockerfile first.\n\n### Configuring Docker Settings\n- Use `DockerSettings` to customize builds at pipeline or step levels.\n- YAML configuration can also be used for better separation of code and settings.\n\n### Managing Dependencies\n- ZenML installs dependencies in a specific order, including local packages, stack requirements, and specified requirements.\n\n### Best Practices\n1. Use code repositories for collaboration and faster builds.\n2. Keep dependencies minimal.\n3. Use `.dockerignore` to reduce image size.\n4. Run containers as non-root users for security.\n\n### Build Reuse and Optimization\n- ZenML reuses builds to save time. Specify build IDs to force new builds if needed.",
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts/containerization#understanding-docker-builds-in-zenml",
        "https://docs.zenml.io/concepts/containerization#docker-build-process",
        "https://docs.zenml.io/concepts/containerization#requirements-installation-order",
        "https://docs.zenml.io/concepts/containerization#configuring-docker-settings",
        "https://docs.zenml.io/concepts/containerization#pipeline-level-settings",
        "https://docs.zenml.io/concepts/containerization#step-level-settings",
        "https://docs.zenml.io/concepts/containerization#using-yaml-configuration",
        "https://docs.zenml.io/concepts/containerization#specifying-docker-build-options",
        "https://docs.zenml.io/concepts/containerization#using-custom-parent-images",
        "https://docs.zenml.io/concepts/containerization#pre-built-parent-images",
        "https://docs.zenml.io/concepts/containerization#skip-build-process",
        "https://docs.zenml.io/concepts/containerization#custom-dockerfiles",
        "https://docs.zenml.io/concepts/containerization#managing-dependencies",
        "https://docs.zenml.io/concepts/containerization#python-dependencies",
        "https://docs.zenml.io/concepts/containerization#system-packages",
        "https://docs.zenml.io/concepts/containerization#installation-control",
        "https://docs.zenml.io/concepts/containerization#private-pypi-repositories",
        "https://docs.zenml.io/concepts/containerization#source-code-management",
        "https://docs.zenml.io/concepts/containerization#controlling-included-files",
        "https://docs.zenml.io/concepts/containerization#environment-variables",
        "https://docs.zenml.io/concepts/containerization#build-reuse-and-optimization",
        "https://docs.zenml.io/concepts/containerization#what-is-a-pipeline-build",
        "https://docs.zenml.io/concepts/containerization#reusing-builds",
        "https://docs.zenml.io/concepts/containerization#controlling-image-repository-names",
        "https://docs.zenml.io/concepts/containerization#specifying-image-tags",
        "https://docs.zenml.io/concepts/containerization#decoupling-code-from-builds",
        "https://docs.zenml.io/concepts/containerization#image-build-location",
        "https://docs.zenml.io/concepts/containerization#container-user-permissions",
        "https://docs.zenml.io/concepts/containerization#best-practices",
        "https://docs.zenml.io/concepts",
        "https://docs.zenml.io/stacks/orchestrators",
        "https://docs.zenml.io/stacks/step-operators",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-config.html#zenml.config.DockerSettings",
        "https://docs.zenml.io/concepts/steps_and_pipelines/configuration",
        "https://docs.zenml.io/concepts/steps_and_pipelines/sources#source-root",
        "https://docs.zenml.io/user-guides/production-guide/connect-code-repository",
        "https://sdkdocs.zenml.io/latest/cli.html#zenml.cli.Pipeline.build",
        "https://docs.zenml.io/concepts/containerization#id-1.-using-the-artifact-store-to-upload-code",
        "https://docs.zenml.io/concepts/containerization#id-2.-using-code-repositories-for-faster-builds",
        "https://docs.zenml.io/concepts/containerization#detecting-local-code-repository-checkouts",
        "https://docs.zenml.io/concepts/containerization#tracking-code-versions-for-pipeline-runs",
        "https://docs.zenml.io/concepts/containerization#preventing-build-reuse",
        "https://docs.zenml.io/concepts/containerization#tips-and-best-practices-for-build-reuse",
        "https://sdkdocs.zenml.io/latest/index.html#zenml.config.DockerSettings",
        "https://docs.zenml.io/stacks/image-builders",
        "https://docs.zenml.io/stacks/image-builders/local",
        "https://docs.zenml.io/user-guides/best-practices/configure-python-environments#client-environment-or-the-runner-environment",
        "https://docs.zenml.io/user-guides/production-guide/understand-stacks",
        "https://docs.zenml.io/concepts/deployment/deployment_settings",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=5aBlTJNbVDkrxJp7J1J9",
        "https://www.docker.com/",
        "https://hub.docker.com/r/zenmldocker/zenml/",
        "https://docker-py.readthedocs.io/en/stable/images.html#docker.models.images.ImageCollection.build",
        "https://github.com/zenml-io/zenml/blob/main/docker/base.Dockerfile",
        "https://pip.pypa.io/en/stable/reference/requirements-file-format/",
        "https://github.com/zenml-io/zenml-patterns/tree/main/docker-local-pkg",
        "https://docs.astral.sh/uv/guides/integration/pytorch/"
    ]
}