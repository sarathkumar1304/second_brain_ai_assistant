{
    "id": "812bba329d9cab9a418405de2ecfdfcc",
    "metadata": {
        "id": "812bba329d9cab9a418405de2ecfdfcc",
        "url": "https://docs.zenml.io/concepts/artifacts",
        "title": "Artifacts | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Learn how ZenML manages data artifacts, tracks versioning and lineage, and enables effective data flow between steps.",
            "keywords": null,
            "author": null,
            "og:title": "Artifacts | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Learn how ZenML manages data artifacts, tracks versioning and lineage, and enables effective data flow between steps.",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/igcqaPTOHW61fR7AbvHU",
            "twitter:card": "summary_large_image",
            "twitter:title": "Artifacts | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Learn how ZenML manages data artifacts, tracks versioning and lineage, and enables effective data flow between steps.",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/igcqaPTOHW61fR7AbvHU"
        }
    },
    "content": "`Ctrl``k`\n\nGitBook AssistantAsk\n\nProductResourcesGitHubStart free\n\nMore\n\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\n\nGitBook Assistant\n\nGitBook Assistant\n\nWorking...Thinking...\n\nGitBook Assistant\n\n##### Good evening\n\nI'm here to help you with the docs.\n\nWhat is this page about?What should I read next?Can you give an example?\n\n`Ctrl``i`\n\nAI Based on your context\n\nSend\n\n  * Getting Started\n\n    * Welcome to ZenML\n    * Installation\n    * Hello World\n    * Your First AI Pipeline\n    * Core Concepts\n    * System Architecture\n  * Deploying ZenML\n\n    * Deploy\n    * Connect\n    * Manage\n  * Concepts\n\n    * Steps & Pipelines\n    * Artifacts\n\n      * Materializers\n      * Visualizations\n\n    * Stack & Components\n    * Service Connectors\n    * Pipeline Snapshots\n    * Pipeline Deployments\n    * Containerization\n    * Code Repositories\n    * Secrets\n    * Environment Variables\n    * Tags\n    * Metadata\n    * Models\n    * Dashboard\n    * Templates\n  * Reference\n\n    * Community & content\n    * Environment Variables\n    * MCP Docs & llms.txt\n    * FAQ\n    * Global settings\n    * Legacy docs\n\n\n\nPowered by GitBook\n\nOn this page\n\n  * Artifacts in the Pipeline Workflow\n  * Basic Artifact Usage\n  * Creating Artifacts (Step Outputs)\n  * Consuming Artifacts (Step Inputs)\n  * Artifacts vs. Parameters\n  * Accessing Artifacts After Pipeline Runs\n  * Working with Artifact Types\n  * Type Annotations\n  * Returning Multiple Outputs\n  * Naming Your Artifacts\n  * How Artifacts Work Under the Hood\n  * Materializers: How Data Gets Stored\n  * Lineage and Caching\n  * Advanced Artifact Usage\n  * Accessing Artifacts from Previous Runs\n  * Cross-Pipeline Artifact Usage\n  * Visualizing Artifacts\n  * Managing Artifacts\n  * Registering Existing Data as Artifacts\n  * Conclusion\n\n\n\nWas this helpful?\n\nGitBook AssistantAsk\n\n  1. Concepts\n\n\n\n# Artifacts\n\nLearn how ZenML manages data artifacts, tracks versioning and lineage, and enables effective data flow between steps.\n\nArtifacts are a cornerstone of ZenML's ML pipeline management system. This guide explains what artifacts are, how they work, and how to use them effectively in your pipelines.\n\n### \n\nArtifacts in the Pipeline Workflow\n\nHere's how artifacts fit into the ZenML pipeline workflow:\n\n  1. A step produces data as output\n\n  2. ZenML automatically stores this output as an artifact\n\n  3. Other steps can use this artifact as input\n\n  4. ZenML tracks the relationships between artifacts and steps\n\n\n\n\nThis system creates a complete data lineage for every artifact in your ML workflows, enabling reproducibility and traceability.\n\n## \n\nBasic Artifact Usage\n\n### \n\nCreating Artifacts (Step Outputs)\n\nAny value returned from a step becomes an artifact:\n\nCopy```\nfrom zenml import pipeline, step\nimport pandas as pd\n@step\ndefcreate_data() -> pd.DataFrame:\n\"\"\"Creates a dataframe that becomes an artifact.\"\"\"\nreturn pd.DataFrame({\n\"feature_1\": [1, 2, 3],\n\"feature_2\": [4, 5, 6],\n\"target\": [10, 20, 30]\n  })\n@step\ndefcreate_prompt_template() ->str:\n\"\"\"Creates a prompt template that becomes an artifact.\"\"\"\nreturn\"\"\"\n  You are a helpful customer service agent. \n  Customer Query: {query}\n  Previous Context: {context}\n  Please provide a helpful response following our company guidelines.\n  \"\"\"\n```\n\n\n### \n\nConsuming Artifacts (Step Inputs)\n\nYou can use artifacts by receiving them as inputs to other steps:\n\nCopy```\n@step\ndef process_data(df: pd.DataFrame) -> pd.DataFrame:\n  \"\"\"Takes an artifact as input and returns a new artifact.\"\"\"\n  df[\"feature_3\"] = df[\"feature_1\"] * df[\"feature_2\"]\n  return df\n@step\ndef test_agent_response(prompt_template: str, test_query: str) -> dict:\n  \"\"\"Uses a prompt template artifact to test agent responses.\"\"\"\n  filled_prompt = prompt_template.format(\n    query=test_query, \n    context=\"Previous customer complained about delayed shipping\"\n  )\n  # Your agent logic here\n  response = call_llm_agent(filled_prompt)\n  return {\"query\": test_query, \"response\": response, \"prompt_used\": filled_prompt}\n@pipeline\ndef simple_pipeline():\n  \"\"\"Pipeline that creates and processes artifacts.\"\"\"\n  # Traditional ML artifacts\n  data = create_data() # Produces an artifact\n  processed_data = process_data(data) # Uses and produces artifacts\n  # AI agent artifacts\n  prompt = create_prompt_template() # Produces a prompt artifact\n  agent_test = test_agent_response(prompt, \"Where is my order?\") # Uses prompt artifact\n```\n\n\n### \n\nArtifacts vs. Parameters\n\nWhen calling a step, inputs can be either artifacts or parameters:\n\n  * **Artifacts** are outputs from other steps in the pipeline. They are tracked, versioned, and stored in the artifact store.\n\n  * **Parameters** are literal values provided directly to the step. They aren't stored as artifacts but are recorded with the pipeline run.\n\n\n\n\nCopy```\nimport pandas as pd\nfrom zenml import step, pipeline\n@step\ndef train_model(data: pd.DataFrame, learning_rate: float) -> object:\n  \"\"\"Step with both artifact and parameter inputs.\"\"\"\n  # data is an artifact (output from another step)\n  # learning_rate is a parameter (literal value)\n  # Note: create_model would be your own model creation function\n  model = create_model(learning_rate)\n  model.fit(data)\n  return model\n@pipeline\ndef training_pipeline():\n  # data is an artifact\n  data = create_data()\n  # data is passed as an artifact, learning_rate as a parameter\n  model = train_model(data=data, learning_rate=0.01)\n```\n\n\nParameters are limited to JSON-serializable values (numbers, strings, lists, dictionaries, etc.). More complex objects should be passed as artifacts.\n\n### \n\nAccessing Artifacts After Pipeline Runs\n\nYou can access artifacts from completed runs using the ZenML Client:\n\nCopy```\nfrom zenml.client import Client\n# Get a specific run\nclient = Client()\npipeline_run = client.get_pipeline_run(\"<PIPELINE_RUN_ID>\")\n# Get an artifact from a specific step\ntrain_data = pipeline_run.steps[\"split_data\"].outputs[\"train_data\"].load()\n# Use the artifact\nprint(train_data.shape)\n```\n\n\n## \n\nWorking with Artifact Types\n\n### \n\nType Annotations\n\nType annotations are important when working with artifacts as they:\n\n  1. Help ZenML select the appropriate materializer for storage\n\n  2. Validate inputs and outputs at runtime\n\n  3. Document the data flow of your pipeline\n\n\n\n\nCopy```\nfrom typing import Tuple\nimport numpy as np\nimport pandas as pd\nfrom zenml import step\n@step\ndef preprocess_data(df: pd.DataFrame) -> np.ndarray:\n  \"\"\"Type annotation tells ZenML this returns a numpy array.\"\"\"\n  return df.values\n@step\ndef split_data(data: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n  \"\"\"Type annotation tells ZenML this returns a tuple of numpy arrays.\"\"\"\n  split_point = len(data) // 2\n  return data[:split_point], data[split_point:]\n```\n\n\nZenML supports many common data types out of the box:\n\n  * Primitive types (`int`, `float`, `str`, `bool`)\n\n  * Container types (`dict`, `list`, `tuple`)\n\n  * NumPy arrays\n\n  * Pandas DataFrames\n\n  * Many ML model formats (through integrations)\n\n\n\n\n### \n\nReturning Multiple Outputs\n\nSteps can return multiple artifacts using tuples:\n\nCopy```\nfrom typing import Tuple, Annotated\nimport numpy as np\n@step\ndef split_data(\n  data: np.ndarray, \n  target: np.ndarray\n) -> Tuple[\n  Annotated[np.ndarray, \"X_train\"],\n  Annotated[np.ndarray, \"X_test\"],\n  Annotated[np.ndarray, \"y_train\"],\n  Annotated[np.ndarray, \"y_test\"]\n]:\n  \"\"\"Split data into training and testing sets.\"\"\"\n  # Implement split logic\n  X_train, X_test = data[:80], data[80:]\n  y_train, y_test = target[:80], target[80:]\n  return X_train, X_test, y_train, y_test\n```\n\n\nZenML differentiates between:\n\n  * A step with multiple outputs: `return a, b` or `return (a, b)`\n\n  * A step with a single tuple output: `return some_tuple`\n\n\n\n\n### \n\nNaming Your Artifacts\n\nBy default, artifacts are named based on their position or variable name:\n\n  * Single outputs are named `output`\n\n  * Multiple outputs are named `output_0`, `output_1`, etc.\n\n\n\n\nYou can give your artifacts more meaningful names using the `Annotated` type:\n\nCopy```\nfrom typing import Tuple\nfrom typing import Annotated\nimport pandas as pd\nfrom zenml import step\n@step\ndef split_dataset(\n  df: pd.DataFrame\n) -> Tuple[\n  Annotated[pd.DataFrame, \"train_data\"],\n  Annotated[pd.DataFrame, \"test_data\"]\n]:\n  \"\"\"Split a dataframe into training and testing sets.\"\"\"\n  train = df.sample(frac=0.8, random_state=42)\n  test = df.drop(train.index)\n  return train, test\n```\n\n\nYou can even use dynamic naming with placeholders:\n\nCopy```\nfrom typing import Annotated\nimport pandas as pd\nfrom zenml import step, pipeline\n@step\ndef extract_data(source: str) -> Annotated[pd.DataFrame, \"{dataset_type}_data\"]:\n  \"\"\"Extract data with a dynamically named output.\"\"\"\n  # Implementation...\n  data = pd.DataFrame() # Your data extraction logic here\n  return data\n@pipeline\ndef data_pipeline():\n  # These will create artifacts named \"train_data\" and \"test_data\"\n  train_df = extract_data.with_options(\n    substitutions={\"dataset_type\": \"train\"}\n  )(source=\"train_source\")\n  test_df = extract_data.with_options(\n    substitutions={\"dataset_type\": \"test\"}\n  )(source=\"test_source\")\n```\n\n\nZenML supports these placeholders:\n\n  * `{date}`: Current date (e.g., \"2023_06_15\")\n\n  * `{time}`: Current time (e.g., \"14_30_45_123456\")\n\n  * Custom placeholders can be defined using `substitutions`\n\n\n\n\n## \n\nHow Artifacts Work Under the Hood\n\n### \n\nMaterializers: How Data Gets Stored\n\nMaterializers are a key concept in ZenML's artifact system. They handle:\n\n  * **Serializing data** when saving artifacts to storage\n\n  * **Deserializing data** when loading artifacts from storage\n\n  * **Generating visualizations** for the dashboard\n\n  * **Extracting metadata** for tracking and searching\n\n\n\n\nWhen a step produces an output, ZenML automatically selects the appropriate materializer based on the data type (using type annotations). ZenML includes built-in materializers for common data types like:\n\n  * Primitive types (`int`, `float`, `str`, `bool`)\n\n  * Container types (`dict`, `list`, `tuple`)\n\n  * NumPy arrays, Pandas DataFrames and many other ML-related formats (through integrations)\n\n\n\n\nHere's how materializers work in practice:\n\nCopy```\nfrom zenml import step\nfrom sklearn.linear_model import LinearRegression\n@step\ndef train_model(X_train, y_train) -> LinearRegression:\n  \"\"\"Train a model and return it as an artifact.\"\"\"\n  model = LinearRegression()\n  model.fit(X_train, y_train)\n  return model # ZenML uses a specific materializer for scikit-learn models\n```\n\n\nFor custom data types, you can create your own materializers. See the Materializers guide for details.\n\n### \n\nLineage and Caching\n\nZenML automatically tracks the complete lineage of each artifact:\n\n  * Which step produced it\n\n  * Which pipeline run it belongs to\n\n  * Which other artifacts it depends on\n\n  * Which steps have consumed it\n\n\n\n\nThis lineage tracking enables powerful caching capabilities. When you run a pipeline, ZenML checks if any steps have been run before with the same inputs, code, and configuration. If so, it reuses the cached outputs instead of rerunning the step:\n\nCopy```\n@pipeline\ndef cached_pipeline():\n  # If create_data has been run before with the same code and inputs,\n  # the cached artifact will be used\n  data = create_data()\n  # If process_data has been run before with the same code and inputs\n  # (including the exact same data artifact), the cached output will be used\n  processed_data = process_data(data)\n```\n\n\n## \n\nAdvanced Artifact Usage\n\n### \n\nAccessing Artifacts from Previous Runs\n\nYou can access artifacts from any previous run by name or ID:\n\nCopy```\nfrom zenml.client import Client\n# Get a specific artifact version\nartifact = Client().get_artifact_version(\"my_model\", \"1.0\")\n# Get the latest version of an artifact\nlatest_artifact = Client().get_artifact_version(\"my_model\")\n# Load it into memory\nmodel = latest_artifact.load()\n```\n\n\nYou can also access artifacts within steps:\n\nCopy```\nfrom zenml.client import Client\nfrom zenml import step\n@step\ndef evaluate_against_previous(model, X_test, y_test) -> float:\n  \"\"\"Compare current model with the previous best model.\"\"\"\n  client = Client()\n  # Get the previous best model\n  best_model = client.get_artifact_version(\"best_model\")\n  # Use it for comparison\n  previous_accuracy = best_model.data.score(X_test, y_test)\n  current_accuracy = model.score(X_test, y_test)\n  return current_accuracy - previous_accuracy\n```\n\n\n### \n\nCross-Pipeline Artifact Usage\n\nYou can use artifacts produced by one pipeline in another pipeline:\n\nCopy```\nfrom zenml.client import Client\nfrom zenml import step, pipeline\n@step\ndef use_trained_model(data: pd.DataFrame, model) -> pd.Series:\n  \"\"\"Use a model loaded from a previous pipeline run.\"\"\"\n  return pd.Series(model.predict(data))\n@pipeline\ndef inference_pipeline():\n  # Load data\n  data = load_data()\n  # Get the latest model from another pipeline\n  model = Client().get_artifact_version(\"trained_model\")\n  # Use it for predictions\n  predictions = use_trained_model(data=data, model=model)\n```\n\n\nThis allows you to build modular pipelines that can work together as part of a larger ML system.\n\n### \n\nVisualizing Artifacts\n\nZenML automatically generates visualizations for many types of artifacts, viewable in the dashboard:\n\nCopy```\n# You can also view visualizations in notebooks\nfrom zenml.client import Client\nartifact = Client().get_artifact_version(\"<ARTIFACT_NAME>\")\nartifact.visualize()\n```\n\n\nFor detailed information on visualizations, see Visualizations.\n\n### \n\nManaging Artifacts\n\nIndividual artifacts cannot be deleted directly (to prevent broken references). However, you can clean up unused artifacts:\n\nCopy```\nzenml artifact prune\n```\n\n\nThis deletes artifacts that are no longer referenced by any pipeline run. You can control this behavior with flags:\n\n  * `--only-artifact`: Only delete the physical files, keep database entries\n\n  * `--only-metadata`: Only delete database entries, keep files\n\n  * `--ignore-errors`: Continue pruning even if some artifacts can't be deleted\n\n\n\n\n### \n\nRegistering Existing Data as Artifacts\n\nSometimes, you may have data created externally (outside of ZenML pipelines) that you want to use within your ZenML workflows. Instead of reading and materializing this data within a step, you can register existing files or folders as ZenML artifacts directly.\n\n#### \n\nRegister an Existing Folder\n\nTo register a folder as a ZenML artifact:\n\nCopy```\nfrom zenml.client import Client\nfrom zenml import register_artifact\nimport os\nfrom pathlib import Path\n# Path to an existing folder in your artifact store\nprefix = Client().active_stack.artifact_store.path\nexisting_folder = os.path.join(prefix, \"my_folder\")\n# Register it as a ZenML artifact\nregister_artifact(\n  folder_or_file_uri=existing_folder,\n  name=\"my_folder_artifact\"\n)\n# Later, load the artifact\nfolder_path = Client().get_artifact_version(\"my_folder_artifact\").load()\nassert isinstance(folder_path, Path)\nassert os.path.isdir(folder_path)\n```\n\n\n#### \n\nRegister an Existing File\n\nSimilarly, you can register individual files:\n\nCopy```\nfrom zenml.client import Client\nfrom zenml import register_artifact\nimport os\nfrom pathlib import Path\n# Path to an existing file in your artifact store\nprefix = Client().active_stack.artifact_store.path\nexisting_file = os.path.join(prefix, \"my_folder/model.pkl\")\n# Register it as a ZenML artifact\nregister_artifact(\n  folder_or_file_uri=existing_file,\n  name=\"my_model_artifact\"\n)\n# Later, load the artifact\nfile_path = Client().get_artifact_version(\"my_model_artifact\").load()\nassert isinstance(file_path, Path)\nassert not os.path.isdir(file_path)\n```\n\n\nThis approach is particularly useful for:\n\n  * Integrating with external ML frameworks that save their own data\n\n  * Working with pre-existing datasets\n\n  * Registering model checkpoints created during training\n\n\n\n\nWhen you load these artifacts, you'll receive a `pathlib.Path` pointing to a temporary location in your executing environment, ready for use as a normal local path.\n\n#### \n\nRegister Framework Checkpoints\n\nA common use case is registering model checkpoints from training frameworks like PyTorch Lightning:\n\nCopy```\nimport os\nfrom uuid import uuid4\nfrom zenml.client import Client\nfrom zenml import register_artifact\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n# Define checkpoint location in your artifact store\nprefix = Client().active_stack.artifact_store.path\ncheckpoint_dir = os.path.join(prefix, uuid4().hex)\n# Configure PyTorch Lightning trainer with checkpointing\nmodel = YourLightningModel()\ntrainer = Trainer(\n  default_root_dir=checkpoint_dir,\n  callbacks=[\n    ModelCheckpoint(\n      every_n_epochs=1, \n      save_top_k=-1, # Keep all checkpoints\n      filename=\"checkpoint-{epoch:02d}\"\n    )\n  ],\n)\n# Train the model\ntrainer.fit(model)\n# Register all checkpoints as a ZenML artifact\nregister_artifact(\n  folder_or_file_uri=checkpoint_dir, \n  name=\"lightning_checkpoints\"\n)\n# Later, you can load the checkpoint folder\ncheckpoint_path = Client().get_artifact_version(\"lightning_checkpoints\").load()\n```\n\n\nYou can also extend the `ModelCheckpoint` callback to register each checkpoint as a separate artifact version during training. This approach enables better version control of intermediate checkpoints.\n\n## \n\nConclusion\n\nArtifacts are a central part of ZenML's approach to ML pipelines. They provide:\n\n  * Automatic versioning and lineage tracking\n\n  * Efficient storage and caching\n\n  * Type-safe data handling\n\n  * Visualization capabilities\n\n  * Cross-pipeline data sharing\n\n\n\n\nWhether you're working with traditional ML models, prompt templates, agent configurations, or evaluation datasets, ZenML's artifact system treats them all uniformly. This enables you to apply the same MLOps principles across your entire AI stack - from classical ML to complex multi-agent systems.\n\nBy understanding how artifacts work, you can build more effective, maintainable, and reproducible ML pipelines and AI workflows.\n\nFor more information on specific aspects of artifacts, see:\n\n  * Materializers: Creating custom serializers for your data types\n\n  * Visualizations: Customizing artifact visualizations\n\n\n\n\nPreviousDynamic Pipelines (Experimental)NextMaterializers\n\nLast updated 5 months ago\n\nWas this helpful?\n",
    "summary": "## TL;DR Summary of ZenML Artifacts Documentation\n\n### Artifacts in the Pipeline Workflow\n- Artifacts are outputs from steps in ZenML pipelines, automatically stored and tracked for lineage and reproducibility.\n\n### Basic Artifact Usage\n- **Creating Artifacts**: Outputs from steps become artifacts.\n- **Consuming Artifacts**: Artifacts can be inputs to other steps.\n- **Artifacts vs. Parameters**: Artifacts are tracked outputs; parameters are direct inputs.\n\n### Accessing Artifacts\n- Artifacts from completed runs can be accessed via the ZenML Client.\n\n### Working with Artifact Types\n- Type annotations help ZenML manage data types and validate inputs/outputs.\n\n### Advanced Artifact Usage\n- Artifacts can be accessed from previous runs and shared across pipelines.\n- Visualizations for artifacts are automatically generated.\n\n### Managing Artifacts\n- Artifacts cannot be deleted directly but can be pruned.\n\n### Registering Existing Data\n- External data can be registered as artifacts for use in ZenML workflows.\n\n### Conclusion\n- Artifacts enable efficient ML pipeline management with versioning, lineage tracking, and cross-pipeline sharing.",
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/artifacts/materializers",
        "https://docs.zenml.io/concepts/artifacts/visualizations",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts/artifacts#artifacts-in-the-pipeline-workflow",
        "https://docs.zenml.io/concepts/artifacts#basic-artifact-usage",
        "https://docs.zenml.io/concepts/artifacts#creating-artifacts-step-outputs",
        "https://docs.zenml.io/concepts/artifacts#consuming-artifacts-step-inputs",
        "https://docs.zenml.io/concepts/artifacts#artifacts-vs.-parameters",
        "https://docs.zenml.io/concepts/artifacts#accessing-artifacts-after-pipeline-runs",
        "https://docs.zenml.io/concepts/artifacts#working-with-artifact-types",
        "https://docs.zenml.io/concepts/artifacts#type-annotations",
        "https://docs.zenml.io/concepts/artifacts#returning-multiple-outputs",
        "https://docs.zenml.io/concepts/artifacts#naming-your-artifacts",
        "https://docs.zenml.io/concepts/artifacts#how-artifacts-work-under-the-hood",
        "https://docs.zenml.io/concepts/artifacts#materializers-how-data-gets-stored",
        "https://docs.zenml.io/concepts/artifacts#lineage-and-caching",
        "https://docs.zenml.io/concepts/artifacts#advanced-artifact-usage",
        "https://docs.zenml.io/concepts/artifacts#accessing-artifacts-from-previous-runs",
        "https://docs.zenml.io/concepts/artifacts#cross-pipeline-artifact-usage",
        "https://docs.zenml.io/concepts/artifacts#visualizing-artifacts",
        "https://docs.zenml.io/concepts/artifacts#managing-artifacts",
        "https://docs.zenml.io/concepts/artifacts#registering-existing-data-as-artifacts",
        "https://docs.zenml.io/concepts/artifacts#conclusion",
        "https://docs.zenml.io/concepts",
        "https://docs.zenml.io/concepts/artifacts#register-an-existing-folder",
        "https://docs.zenml.io/concepts/artifacts#register-an-existing-file",
        "https://docs.zenml.io/concepts/artifacts#register-framework-checkpoints",
        "https://docs.zenml.io/concepts/steps_and_pipelines/dynamic_pipelines",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=5aBlTJNbVDkrxJp7J1J9"
    ]
}