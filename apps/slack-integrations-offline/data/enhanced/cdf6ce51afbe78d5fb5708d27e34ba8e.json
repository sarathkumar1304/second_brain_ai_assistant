{
    "id": "cdf6ce51afbe78d5fb5708d27e34ba8e",
    "metadata": {
        "id": "cdf6ce51afbe78d5fb5708d27e34ba8e",
        "url": "https://docs.zenml.io/concepts/metadata",
        "title": "Metadata | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Enrich your ML workflow with contextual information using ZenML metadata.",
            "keywords": null,
            "author": null,
            "og:title": "Metadata | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Enrich your ML workflow with contextual information using ZenML metadata.",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/f7HLo3clsWGy1vESOPP2",
            "twitter:card": "summary_large_image",
            "twitter:title": "Metadata | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Enrich your ML workflow with contextual information using ZenML metadata.",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/f7HLo3clsWGy1vESOPP2"
        }
    },
    "content": "`Ctrl``k`\n\nGitBook AssistantAsk\n\nProductResourcesGitHubStart free\n\nMore\n\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\n\nGitBook Assistant\n\nGitBook Assistant\n\nWorking...Thinking...\n\nGitBook Assistant\n\n##### Good evening\n\nI'm here to help you with the docs.\n\nWhat is this page about?What should I read next?Can you give an example?\n\n`Ctrl``i`\n\nAI Based on your context\n\nSend\n\n  * Getting Started\n\n    * Welcome to ZenML\n    * Installation\n    * Hello World\n    * Your First AI Pipeline\n    * Core Concepts\n    * System Architecture\n  * Deploying ZenML\n\n    * Deploy\n    * Connect\n    * Manage\n  * Concepts\n\n    * Steps & Pipelines\n    * Artifacts\n    * Stack & Components\n    * Service Connectors\n    * Pipeline Snapshots\n    * Pipeline Deployments\n    * Containerization\n    * Code Repositories\n    * Secrets\n    * Environment Variables\n    * Tags\n    * Metadata\n    * Models\n    * Dashboard\n    * Templates\n  * Reference\n\n    * Community & content\n    * Environment Variables\n    * MCP Docs & llms.txt\n    * FAQ\n    * Global settings\n    * Legacy docs\n\n\n\nPowered by GitBook\n\nOn this page\n\n  * Logging Metadata\n  * Attaching Metadata to Steps\n  * Attaching Metadata to Pipeline Runs\n  * Attaching Metadata to Artifacts\n  * Attaching Metadata to Models\n  * Bulk Metadata Logging\n  * Performance improvements hints\n  * Using the client directly\n  * Special Metadata Types\n  * Organizing Metadata in the Dashboard\n  * Visualizing and Comparing Metadata (Pro)\n  * Comparison Views\n  * Fetching Metadata\n  * Retrieving Metadata Programmatically\n  * Accessing Context Within Steps\n  * Working with outputs\n  * Accessing Context During Pipeline Composition\n  * Best Practices\n  * Conclusion\n\n\n\nWas this helpful?\n\nGitBook AssistantAsk\n\n  1. Concepts\n\n\n\n# Metadata\n\nEnrich your ML workflow with contextual information using ZenML metadata.\n\nMetadata in ZenML provides critical context to your ML workflows, allowing you to track additional information about your steps, runs, artifacts, and models. This enhanced traceability helps you better understand, compare, and reproduce your experiments.\n\nMetadata in the dashboard\n\nMetadata is any additional contextual information you want to associate with your ML workflow components. In ZenML, you can attach metadata to:\n\n  * **Steps** : Log evaluation metrics, execution details, or configuration information\n\n  * **Pipeline Runs** : Track overall run characteristics like environment variables or git information\n\n  * **Artifacts** : Document data characteristics, source information, or processing details\n\n  * **Models** : Capture evaluation results, hyperparameters, or deployment information\n\n\n\n\nZenML makes it easy to log and retrieve this information through a simple interface, and visualizes it in the dashboard for quick analysis.\n\n## \n\nLogging Metadata\n\nThe primary way to log metadata in ZenML is through the `log_metadata` function, which allows you to attach JSON-serializable key-value pairs to various entities.\n\nMetadata supports primitive types (`str`, `int`, `float`, `bool`), collections (`list`, `dict`, `set`, `tuple`), and special ZenML types (`Uri`, `Path`, `DType`, `StorageSize`). Sets and tuples are automatically converted to lists during storage.\n\nCopy```\nfrom zenml import log_metadata\n# Basic metadata logging\nlog_metadata(\n  metadata={\"accuracy\": 0.95, \"precision\": 0.92},\n  # Additional parameters to specify where to log the metadata\n)\n```\n\n\nThe `log_metadata` function is versatile and can target different entities depending on the parameters provided.\n\n### \n\nAttaching Metadata to Steps\n\nTo log metadata for a step, you can either call `log_metadata` within the step (which automatically associates with the current step), or specify a step explicitly:\n\nCopy```\nfrom zenml import step, log_metadata\n# Method 1: Within a step (automatically associates with current step)\n@step\ndef train_model_step(data):\n  model = train_model(data)\n  accuracy = evaluate_model(model, data)\n  # Log metrics directly within the step\n  log_metadata(\n    metadata={\"evaluation_metrics\": {\"accuracy\": accuracy}}\n  )\n  return model\n# Method 2: Targeting a specific step after execution\nlog_metadata(\n  metadata={\"post_analysis\": {\"feature_importance\": [0.2, 0.5, 0.3]}},\n  step_name=\"train_model_step\",\n  run_id_name_or_prefix=\"my_run_id\"\n)\n# Alternative: Using step_id\nlog_metadata(\n  metadata={\"post_analysis\": {\"feature_importance\": [0.2, 0.5, 0.3]}},\n  step_id=\"step_uuid\"\n)\n```\n\n\n### \n\nAttaching Metadata to Pipeline Runs\n\nYou can log metadata for an entire pipeline run, either from within a step during execution or manually after the run:\n\nCopy```\nfrom zenml import get_step_context, pipeline, step, log_metadata\n# Method 1: Within a step (logs to the current run)\n@step\ndef log_run_info_step():\n  context = get_step_context()\n  # Get some runtime information\n  git_commit = get_git_hash()\n  environment = get_env_info()\n  # Log to the current pipeline run\n  log_metadata(\n    metadata={\n      \"git_info\": {\"commit\": git_commit},\n      \"environment\": environment\n    },\n    run_id_name_or_prefix=context.pipeline_run.id,\n  )\n# Method 2: Manually targeting a specific run\nlog_metadata(\n  metadata={\"post_run_analysis\": {\"total_training_time\": 350}},\n  run_id_name_or_prefix=\"my_run_id\"\n)\n```\n\n\nWhen logging from within a step to the pipeline run, the metadata key will have the pattern `step_name::metadata_key`, allowing multiple steps to use the same metadata key.\n\n### \n\nAttaching Metadata to Artifacts\n\nArtifacts are the data objects produced by pipeline steps. You can log metadata for these artifacts to provide more context about the data:\n\nCopy```\nfrom zenml import step, log_metadata\nfrom zenml.metadata.metadata_types import StorageSize\n# Method 1: Within a step for an output artifact\n@step\ndef process_data_step(raw_data):\n  processed_data = transform(raw_data)\n  # Log metadata for the output artifact (when step has single output)\n  log_metadata(\n    metadata={\n      \"data_stats\": {\n        \"row_count\": len(processed_data),\n        \"columns\": list(processed_data.columns),\n        \"storage_size\": StorageSize(processed_data.memory_usage().sum())\n      }\n    },\n    infer_artifact=True # Automatically target the output artifact\n  )\n  return processed_data\n# Method 2: For a step with multiple outputs\n@step\ndef split_data_step(data):\n  train, test = split_data(data)\n  # Log metadata for specific output by name\n  log_metadata(\n    metadata={\"split_info\": {\"train_size\": len(train)}},\n    artifact_name=\"output_0\", # Name of the specific output\n    infer_artifact=True\n  )\n  return train, test\n# Method 3: Explicitly target an artifact by name and version\nlog_metadata(\n  metadata={\"validation_results\": {\"distribution_shift\": 0.03}},\n  artifact_name=\"processed_data\",\n  artifact_version=\"20230615\"\n)\n# Method 4: Target by artifact version ID\nlog_metadata(\n  metadata={\"validation_results\": {\"distribution_shift\": 0.03}},\n  artifact_version_id=\"artifact_uuid\"\n)\n```\n\n\n### \n\nAttaching Metadata to Models\n\nModels in ZenML represent a higher-level concept that can encapsulate multiple artifacts and steps. Logging metadata for models helps track performance and other important information:\n\nCopy```\nfrom zenml import step, log_metadata\n# Method 1: Within a step that produces a model\n@step\ndef train_model_step(data):\n  model = train_model(data)\n  metrics = evaluate_model(model, data)\n  # Log metadata to the model\n  log_metadata(\n    metadata={\n      \"evaluation_metrics\": metrics,\n      \"hyperparameters\": model.get_params()\n    },\n    infer_model=True # Automatically target the model associated with this step\n  )\n  return model\n# Method 2: Explicitly target a model by name and version\nlog_metadata(\n  metadata={\"deployment_info\": {\"endpoint\": \"api.example.com/model\"}},\n  model_name=\"fraud_detector\",\n  model_version=\"1.0.0\"\n)\n# Method 3: Target by model version ID\nlog_metadata(\n  metadata={\"deployment_info\": {\"endpoint\": \"api.example.com/model\"}},\n  model_version_id=\"model_version_uuid\"\n)\n```\n\n\n## \n\nBulk Metadata Logging\n\nThe `log_metadata` function does not support logging the same metadata for multiple entities simultaneously. To achieve this, you can use the `bulk_log_metadata` function:\n\nCopy```\nfrom zenml.models import (\n  ArtifactVersionIdentifier,\n  ModelVersionIdentifier,\n  PipelineRunIdentifier,\n  StepRunIdentifier,\n)\nfrom zenml import bulk_log_metadata\nbulk_log_metadata(\n  metadata={\"python_version\": \"3.11\", \"environment\": \"macosx\"},\n  pipeline_runs=[\n    PipelineRunIdentifier(id=\"<run_id>\"),\n    PipelineRunIdentifier(name=\"run name\")\n  ],\n  step_runs=[\n    StepRunIdentifier(id=\"<step_run_id>\"),\n    StepRunIdentifier(name=\"<step_name>\", run=PipelineRunIdentifier(id=\"<run_id>\"))\n  ],\n  artifact_versions=[\n    ArtifactVersionIdentifier(id=\"<artifact_version_id>\"),\n    ArtifactVersionIdentifier(name=\"artifact_name\", version=\"artifact_version\")\n  ],\n  model_versions=[\n    ModelVersionIdentifier(id=\"<model_version_id>\"),\n    ModelVersionIdentifier(name=\"model_name\", version=\"model_version\")\n  ]\n)\n\n```\n\n\nNote that the `bulk_log_metadata` function has a slightly different signature compared to `log_metadata`. You can use the Identifier class objects to specify any parameter combination that uniquely identifies an object:\n\n  * VersionedIdentifiers\n\n    * ArtifactVersionIdentifier & ModelVersionIdentifier\n\n    * Specify either an id or a combination of name and version.\n\n  * PipelineRunIdentifier\n\n    * Specify an id, name, or prefix.\n\n  * StepRunIdentifier\n\n    * Specify an id or a combination of name and a pipeline run identifier.\n\n\n\n\nSimilar to the `log_metadata` function, if you are calling `bulk_log_metadata` from within a step, you can use the infer options to automatically log metadata for the step’s model version or artifacts:\n\nCopy```\nfrom zenml import bulk_log_metadata, step\n@step()\ndef get_train_test_datasets():\n  train_dataset, test_dataset = get_datasets()\n  bulk_log_metadata(\n    metadata={\"python_version\": \"3.11\", \"environment\": \"macosx\"},\n    infer_models=True,\n    infer_artifacts=True\n  )\n  return train_dataset, test_dataset\n```\n\n\nKeep in mind that when using the `infer_artifacts` option, the `bulk_log_metadata` function logs metadata to all output artifacts of the step. When logging metadata, you may need the option to use `infer` options in combination with identifier references. For instance, you may want to log metadata to a step's outputs but also to its inputs. The `bulk_log_metadata` function enables you to use both options in one go:\n\nCopy```\nfrom zenml import bulk_log_metadata, get_step_context, step\nfrom zenml.models import ArtifactVersionIdentifier\ndef calculate_metrics(model, test_dataset):\n  ...\ndef summarize_metrics(metrics_report):\n  ...\n@step\ndef model_evaluation(test_dataset, model):\n  metrics_report = calculate_metrics(model, test_dataset)\n  slim_metrics_version = summarize_metrics(metrics_report)\n  bulk_log_metadata(\n    metadata=slim_metrics_version,\n    infer_artifacts=True, # log metadata for outputs\n    artifact_versions=[\n      ArtifactVersionIdentifier(id=get_step_context().inputs[\"model\"].id)\n    ] # log metadata for the model input\n  )\n  return metrics_report\n```\n\n\n### \n\nPerformance improvements hints\n\nBoth `log_metadata` and `bulk_log_metadata` internally use parameters such as name and version to resolve the actual IDs of entities. For example, when you provide an artifact's name and version, the function performs an additional lookup to resolve the artifact version ID.\n\nTo improve performance, prefer using the entity's ID directly instead of its name, version, or other identifiers whenever possible.\n\n### \n\nUsing the client directly\n\nIf the `log_metadata` or `bulk_log_metadata` functions are too restrictive for your use case, you can use the ZenML Client directly to create run metadata for resources:\n\nCopy```\nfrom zenml.client import Client\nfrom zenml.enums import MetadataResourceTypes\nfrom zenml.models import RunMetadataResource\nclient = Client()\nclient.create_run_metadata(\n  metadata={\"python\": \"3.11\"},\n  resources=[\n    RunMetadataResource(id=\"<step_run_id>\", type=MetadataResourceTypes.STEP_RUN),\n    RunMetadataResource(id=\"<run_id>\", type=MetadataResourceTypes.PIPELINE_RUN),\n    RunMetadataResource(id=\"<artifact_version_id>\", type=MetadataResourceTypes.ARTIFACT_VERSION),\n    RunMetadataResource(id=\"<model_version_id>\", type=MetadataResourceTypes.MODEL_VERSION)\n  ]\n)\n```\n\n\n## \n\nSpecial Metadata Types\n\nZenML includes several special metadata types that provide standardized ways to represent common metadata:\n\nCopy```\nfrom zenml import log_metadata\nfrom zenml.metadata.metadata_types import StorageSize, DType, Uri, Path\nlog_metadata(\n  metadata={\n    \"dataset_source\": Uri(\"gs://my-bucket/datasets/source.csv\"), # External URI\n    \"preprocessing_script\": Path(\"/scripts/preprocess.py\"), # File path\n    \"column_types\": {\n      \"age\": DType(\"int\"), # Data type\n      \"income\": DType(\"float\"),\n      \"score\": DType(\"int\")\n    },\n    \"processed_data_size\": StorageSize(2500000) # Size in bytes\n  },\n  infer_artifact=True\n)\n```\n\n\nThese special types ensure metadata is logged in a consistent and interpretable manner, and they receive special treatment in the ZenML dashboard.\n\n## \n\nOrganizing Metadata in the Dashboard\n\nTo improve visualization in the ZenML dashboard, you can group metadata into logical sections by passing a dictionary of dictionaries:\n\nCopy```\nfrom zenml import log_metadata\nfrom zenml.metadata.metadata_types import StorageSize\nlog_metadata(\n  metadata={\n    \"model_metrics\": { # First card in the dashboard\n      \"accuracy\": 0.95,\n      \"precision\": 0.92,\n      \"recall\": 0.90\n    },\n    \"data_details\": {  # Second card in the dashboard\n      \"dataset_size\": StorageSize(1500000),\n      \"feature_columns\": [\"age\", \"income\", \"score\"]\n    }\n  },\n  artifact_name=\"my_artifact\",\n  artifact_version=\"version\",\n)\n```\n\n\nIn the ZenML dashboard, \"model_metrics\" and \"data_details\" will appear as separate cards, each containing their respective key-value pairs, making it easier to navigate and interpret the metadata.\n\n## \n\nVisualizing and Comparing Metadata (Pro)\n\nOnce you've logged metadata in your runs, you can use ZenML's Experiment Comparison tool to analyze and compare metrics across different run.\n\nThe metadata comparison tool is a ZenML Pro-only feature.\n\n### \n\nComparison Views\n\nThe Experiment Comparison tool offers two complementary views for analyzing your pipeline metadata:\n\n  1. **Table View** : Compare metadata across runs with automatic change tracking\n\n\n\n\nTable View\n\n  1. **Parallel Coordinates Plot** : Visualize relationships between different metrics\n\n\n\n\nParallel Coordinates\n\nThe tool lets you compare up to 20 pipeline runs simultaneously and supports any numerical metadata (`float` or `int`) that you've logged in your pipelines.\n\n## \n\nFetching Metadata\n\n### \n\nRetrieving Metadata Programmatically\n\nOnce metadata has been logged, you can retrieve it using the ZenML Client:\n\nCopy```\nfrom zenml.client import Client\nclient = Client()\n# Get metadata from a step\nstep = client.get_pipeline_run(\"pipeline_run_id\").steps[\"step_name\"]\nstep_metadata = step.run_metadata[\"metadata_key\"]\n# Get metadata from a run\nrun = client.get_pipeline_run(\"pipeline_run_id\")\nrun_metadata = run.run_metadata[\"metadata_key\"]\n# Get metadata from an artifact\nartifact = client.get_artifact_version(\"artifact_name\", \"version\")\nartifact_metadata = artifact.run_metadata[\"metadata_key\"]\n# Get metadata from a model\nmodel = client.get_model_version(\"model_name\", \"version\")\nmodel_metadata = model.run_metadata[\"metadata_key\"]\n```\n\n\nWhen fetching metadata using a specific key, the returned value will always reflect the latest entry for that key.\n\n### \n\nAccessing Context Within Steps\n\nThe `StepContext` object is your handle to the _current_ pipeline/step run while a step executes. Use it to read run/step information, inspect upstream input metadata, and work with step outputs: URIs, materializers, run metadata, and tags.\n\nIt is available:\n\n  * Inside functions decorated with `@step` (during execution, not composition time).\n\n  * Inside step hooks like `on_failure` / `on_success`.\n\n  * Inside materializers triggered by a step’s `save` / `load`.\n\n  * Calling `get_step_context()` elsewhere raises `RuntimeError`.\n\n\n\n\nGetting the context is done via `get_step_context()`:\n\nCopy```\nfrom zenml import step, get_step_context\n@step\ndef trainer(param: int = 1):\n  ctx = get_step_context()\n  print(\"run:\", ctx.pipeline_run.name, ctx.pipeline_run.id)\n  print(\"step:\", ctx.step_run.name,  ctx.step_run.id)\n  print(\"params:\", ctx.step_run.config.parameters)\n```\n\n\nThis exposes the following properties:\n\n  * `ctx.pipeline` → the `PipelineResponse` for this run (convenience; may raise if the run has no pipeline object).\n\n  * `ctx.pipeline_run` → `PipelineRunResponse` (id, name, status, timestamps, etc.).\n\n  * `ctx.step_run` → `StepRunResponse` (name, parameters via `ctx.step_run.config.parameters`, status).\n\n  * `ctx.model` → the configured `Model` (resolved from step or pipeline); raises if none configured.\n\n  * `ctx.inputs` → `{input_name: StepRunInputResponse}`; use `...[\"x\"].run_metadata` to read upstream metadata.\n\n  * `ctx.step_name` → convenience name string.\n\n\n\n\n### \n\nWorking with outputs\n\nFor a single-output step you can omit `output_name`. For multi-output steps you **must** pass it (unnamed outputs are called `output_1`, `output_2`, …).\n\n  * `get_output_artifact_uri(output_name=None) -> str` – where the output artifact lives (write side files, etc.).\n\n  * `get_output_materializer(output_name=None, *, custom_materializer_class=None, data_type=None) -> BaseMaterializer` – get an initialized materializer; pass `data_type` to select from `Union[...]` materializers or `custom_materializer_class` to override.\n\n  * `add_output_metadata(metadata, output_name=None)` / `get_output_metadata(output_name=None)` – set/read run metadata for the output. Values provided via `ArtifactConfig(..., run_metadata=...)` on the return annotation are merged with runtime values.\n\n  * `add_output_tags(tags, output_name=None)` / `get_output_tags(output_name=None)` / `remove_output_tags(tags, output_name=None)` – manage tags for the produced artifact version. Configured tags via `ArtifactConfig(..., tags=...)` are unioned with runtime tags; duplicates are de‑duplicated in the final artifact.\n\n\n\n\nMinimal example:\n\nCopy```\nfrom typing import Annotated, Tuple\nfrom zenml import step, get_step_context, log_metadata\nfrom zenml.artifacts.artifact_config import ArtifactConfig\n@step\ndef produce(name: str) -> Tuple[\n  Annotated[\n    str,\n    ArtifactConfig(\n      name=\"custom_name\",\n      run_metadata={\"config_metadata\": \"bar\"},\n      tags=[\"config_tags\"],\n    ),\n  ],\n  str,\n]:\n  ctx = get_step_context()\n  # Attach metadata and tags to the named (or default) output\n  ctx.add_output_metadata({\"m\": 1}, output_name=name)\n  ctx.add_output_tags([\"t1\", \"t1\"], output_name=name) # duplicates ok\n  return \"a\", \"b\"\n```\n\n\n#### \n\nReading upstream metadata via `inputs`\n\nCopy```\nfrom zenml import step, get_step_context, log_metadata\n@step\ndef upstream() -> int:\n  log_metadata({\"quality\": \"ok\"}, infer_artifact=True)\n  return 42\n@step\ndef downstream(x: int) -> None:\n  md = get_step_context().inputs[\"x\"].run_metadata\n  assert md[\"quality\"] == \"ok\"\n```\n\n\n#### \n\nHooks and materializers (advanced)\n\nCopy```\nfrom zenml import step, get_step_context\nfrom zenml.materializers.base_materializer import BaseMaterializer\ndef on_failure(exc: BaseException):\n  c = get_step_context()\n  print(\"Failed step:\", c.step_run.name, \"-\", type(exc).__name__)\nclass ExampleMaterializer(BaseMaterializer):\n  def save(self, data):\n    # Context is available while the step triggers materialization\n    data.meta = get_step_context().pipeline.name\n    super().save(data)\n@step(on_failure=on_failure)\ndef my_step():\n  raise ValueError(\"boom\")\n```\n\n\n**Common errors to expect.**\n\n  * `RuntimeError` if `get_step_context()` is called outside a running step.\n\n  * `StepContextError` for output helpers when:\n\n    * The step has no outputs,\n\n    * You omit `output_name` on a multi‑output step,\n\n    * You reference an unknown `output_name`.\n\n\n\n\nSee the full SDK docs for `StepContext` for a concise reference to this object.\n\n### \n\nAccessing Context During Pipeline Composition\n\nDuring pipeline composition, you can access the pipeline configuration using the `PipelineContext`:\n\nCopy```\nfrom zenml import pipeline, get_pipeline_context\n@pipeline(\n  extra={\n    \"model_configs\": [\n      (\"sklearn.tree\", \"DecisionTreeClassifier\"),\n      (\"sklearn.ensemble\", \"RandomForestClassifier\"),\n    ]\n  }\n)\ndef my_pipeline():\n  # Get the pipeline context\n  context = get_pipeline_context()\n  # Access the configuration\n  model_configs = context.extra[\"model_configs\"]\n  # Use the configuration to dynamically create steps\n  for i, (model_package, model_class) in enumerate(model_configs):\n    train_model(\n      model_package=model_package,\n      model_class=model_class,\n      id=f\"train_model_{i}\"\n    )\n```\n\n\n## \n\nBest Practices\n\nTo make the most of ZenML's metadata capabilities:\n\n  1. **Use consistent keys** : Define standard metadata keys for your organization to ensure consistency\n\n  2. **Group related metadata** : Use nested dictionaries to create logical groupings in the dashboard\n\n  3. **Leverage special types** : Use ZenML's special metadata types for standardized representation\n\n  4. **Log relevant information** : Focus on metadata that aids reproducibility, understanding, and decision-making\n\n  5. **Consider automation** : Set up automatic metadata logging for standard metrics and information\n\n  6. **Combine with tags** : Use metadata alongside tags for a comprehensive organization system\n\n\n\n\n## \n\nConclusion\n\nMetadata in ZenML provides a powerful way to enhance your ML workflows with contextual information. By tracking additional details about your steps, runs, artifacts, and models, you can gain deeper insights into your experiments, make more informed decisions, and ensure reproducibility of your ML pipelines.\n\nPreviousTagsNextModels\n\nLast updated 11 days ago\n\nWas this helpful?\n",
    "summary": "## TL;DR Summary of ZenML Metadata Documentation\n\n### Metadata Overview\n- **Purpose**: Enhance ML workflows with contextual information for better traceability and reproducibility.\n- **Components**: Attach metadata to Steps, Pipeline Runs, Artifacts, and Models.\n\n### Logging Metadata\n- **Function**: Use `log_metadata` to attach JSON-serializable key-value pairs.\n- **Types Supported**: Primitive types, collections, and special ZenML types (e.g., `Uri`, `Path`).\n\n### Attaching Metadata\n- **Steps**: Log metrics directly within a step or target a specific step post-execution.\n- **Pipeline Runs**: Log metadata during or after execution.\n- **Artifacts**: Provide context about data characteristics.\n- **Models**: Capture performance metrics and deployment info.\n\n### Bulk Logging\n- Use `bulk_log_metadata` for simultaneous logging across multiple entities.\n\n### Performance Tips\n- Prefer using entity IDs over names/versions for efficiency.\n\n### Special Metadata Types\n- Standardized types for consistent representation (e.g., `StorageSize`, `DType`).\n\n### Best Practices\n- Use consistent keys, group related metadata, and automate logging for reproducibility.\n\n### Conclusion\n- Metadata in ZenML is crucial for gaining insights and ensuring reproducibility in ML experiments.",
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts/metadata#logging-metadata",
        "https://docs.zenml.io/concepts/metadata#attaching-metadata-to-steps",
        "https://docs.zenml.io/concepts/metadata#attaching-metadata-to-pipeline-runs",
        "https://docs.zenml.io/concepts/metadata#attaching-metadata-to-artifacts",
        "https://docs.zenml.io/concepts/metadata#attaching-metadata-to-models",
        "https://docs.zenml.io/concepts/metadata#bulk-metadata-logging",
        "https://docs.zenml.io/concepts/metadata#performance-improvements-hints",
        "https://docs.zenml.io/concepts/metadata#using-the-client-directly",
        "https://docs.zenml.io/concepts/metadata#special-metadata-types",
        "https://docs.zenml.io/concepts/metadata#organizing-metadata-in-the-dashboard",
        "https://docs.zenml.io/concepts/metadata#visualizing-and-comparing-metadata-pro",
        "https://docs.zenml.io/concepts/metadata#comparison-views",
        "https://docs.zenml.io/concepts/metadata#fetching-metadata",
        "https://docs.zenml.io/concepts/metadata#retrieving-metadata-programmatically",
        "https://docs.zenml.io/concepts/metadata#accessing-context-within-steps",
        "https://docs.zenml.io/concepts/metadata#working-with-outputs",
        "https://docs.zenml.io/concepts/metadata#accessing-context-during-pipeline-composition",
        "https://docs.zenml.io/concepts/metadata#best-practices",
        "https://docs.zenml.io/concepts/metadata#conclusion",
        "https://docs.zenml.io/concepts",
        "https://zenml.io/pro",
        "https://docs.zenml.io/concepts/metadata#reading-upstream-metadata-via-inputs",
        "https://docs.zenml.io/concepts/metadata#hooks-and-materializers-advanced",
        "https://sdkdocs.zenml.io/latest/core_code_docs/core-steps.html#zenml.steps.StepContext",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=5aBlTJNbVDkrxJp7J1J9",
        "https://www.loom.com/share/693b2d829600492da7cd429766aeba6a?sid=7182e55b-31e9-4b38-a3be-07c989dbea32"
    ]
}