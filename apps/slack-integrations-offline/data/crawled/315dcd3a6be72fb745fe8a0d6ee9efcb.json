{
    "id": "315dcd3a6be72fb745fe8a0d6ee9efcb",
    "metadata": {
        "id": "315dcd3a6be72fb745fe8a0d6ee9efcb",
        "url": "https://docs.zenml.io/concepts/models",
        "title": "Models | ZenML - Bridging the gap between ML & Ops",
        "properties": {
            "description": "Managing ML models throughout their lifecycle with ZenML",
            "keywords": null,
            "author": null,
            "og:title": "Models | ZenML - Bridging the gap between ML & Ops",
            "og:description": "Managing ML models throughout their lifecycle with ZenML",
            "og:image": "https://docs.zenml.io/~gitbook/ogimage/lI4tMC1CZZws8pPsQOvF",
            "twitter:card": "summary_large_image",
            "twitter:title": "Models | ZenML - Bridging the gap between ML & Ops",
            "twitter:description": "Managing ML models throughout their lifecycle with ZenML",
            "twitter:image": "https://docs.zenml.io/~gitbook/ogimage/lI4tMC1CZZws8pPsQOvF"
        }
    },
    "content": "`Ctrl``k`\n\nGitBook AssistantAsk\n\nProductResourcesGitHubStart free\n\nMore\n\n  * Documentation\n  * Learn\n  * ZenML Pro\n  * Stacks\n  * API Reference\n  * SDK Reference\n  * Changelog\n\n\n\nGitBook Assistant\n\nGitBook Assistant\n\nWorking...Thinking...\n\nGitBook Assistant\n\n##### Good evening\n\nI'm here to help you with the docs.\n\nWhat is this page about?What should I read next?Can you give an example?\n\n`Ctrl``i`\n\nAI Based on your context\n\nSend\n\n  * Getting Started\n\n    * Welcome to ZenML\n    * Installation\n    * Hello World\n    * Your First AI Pipeline\n    * Core Concepts\n    * System Architecture\n  * Deploying ZenML\n\n    * Deploy\n    * Connect\n    * Manage\n  * Concepts\n\n    * Steps & Pipelines\n    * Artifacts\n    * Stack & Components\n    * Service Connectors\n    * Pipeline Snapshots\n    * Pipeline Deployments\n    * Containerization\n    * Code Repositories\n    * Secrets\n    * Environment Variables\n    * Tags\n    * Metadata\n    * Models\n    * Dashboard\n    * Templates\n  * Reference\n\n    * Community & content\n    * Environment Variables\n    * MCP Docs & llms.txt\n    * FAQ\n    * Global settings\n    * Legacy docs\n\n\n\nPowered by GitBook\n\nOn this page\n\n  * Understanding Models in ZenML\n  * What is a ZenML Model?\n  * The Model Control Plane\n  * Working with Models\n  * Registering a Model\n  * Model Versioning\n  * Linking Artifacts to Models\n  * Model Promotion\n  * Using Models Across Pipelines\n  * Pattern: Model-Mediated Artifact Exchange\n  * Tracking Metrics and Metadata\n  * Logging Model Metadata\n  * Fetching Model Metadata\n  * Deleting Models\n  * Deleting All Versions of a Model\n  * Deleting a Specific Version\n  * Best Practices\n  * Conclusion\n\n\n\nWas this helpful?\n\nGitBook AssistantAsk\n\n  1. Concepts\n\n\n\n# Models\n\nManaging ML models throughout their lifecycle with ZenML\n\nMachine learning models and AI agent configurations are at the heart of any ML workflow and AI system. ZenML provides comprehensive model management capabilities through its Model Control Plane, allowing you to track, version, promote, and share both traditional ML models and AI agent systems across your pipelines.\n\nThe ZenML Model Control Plane is a ZenML Pro feature. While the Python functions for creating and interacting with models are available in the open-source version, the visual dashboard for exploring and managing models is only available in ZenML Pro. Please sign up here to get access to the full model management experience.\n\nThis guide covers all aspects of working with models in ZenML, from basic concepts to advanced usage patterns.\n\n## \n\nUnderstanding Models in ZenML\n\n### \n\nWhat is a ZenML Model?\n\nA ZenML Model is an entity that groups together related resources:\n\n  * Pipelines that train, evaluate, or deploy the model or agent system\n\n  * Artifacts like datasets, model weights, predictions, prompt templates, and agent configurations\n\n  * Metadata including metrics, parameters, evaluation results, and business information\n\n\n\n\nThink of a ZenML Model as a container that organizes all the components related to a specific ML use case, business problem, or AI agent system. This extends beyond just model weights or agent prompts - it represents the entire ML product or intelligent system.\n\nA ZenML Model is different from a \"technical model\" (the actual ML model files with weights and parameters) or \"agent configuration\" (prompt templates, tool definitions, etc.). These technical artifacts are just components that can be associated with a ZenML Model, alongside training data, predictions, evaluation results, and other resources.\n\n### \n\nThe Model Control Plane\n\nThe Model Control Plane is ZenML's unified interface for managing models throughout their lifecycle. It allows you to:\n\n  * Register and version models\n\n  * Associate pipelines and artifacts with models\n\n  * Track lineage and dependencies\n\n  * Manage model promotions through stages (staging, production, etc.)\n\n  * Exchange data between pipelines using models\n\n\n\n\nWhile all Model Control Plane functionality is accessible programmatically through the Python SDK in both OSS and Pro versions, the visual dashboard shown below is only available in ZenML Pro.\n\nModel Control Plane Overview in ZenML Pro Dashboard\n\n## \n\nWorking with Models\n\n### \n\nRegistering a Model\n\nYou can register models in several ways:\n\n#### \n\nUsing the Python SDK\n\nCopy```\nfrom zenml import Model\nfrom zenml.client import Client\nClient().create_model(\n  name=\"customer_service_agent\",\n  license=\"MIT\",\n  description=\"Multi-agent system for customer service automation\",\n  tags=[\"agent\", \"customer-service\", \"llm\", \"rag\"],\n)\n```\n\n\n#### \n\nUsing the CLI\n\nCopy```\nzenml model register customer_service_agent --license=\"MIT\" --description=\"Multi-agent customer service system\"\n```\n\n\n#### \n\nUsing a Pipeline\n\nThe most common approach is to register a model implicitly as part of a pipeline:\n\nCopy```\nfrom zenml import pipeline, Model\n@pipeline(\n  model=Model(\n    name=\"iris_classifier\",\n    description=\"Classification model for the Iris dataset\",\n    tags=[\"classification\", \"sklearn\"]\n  )\n)\ndef training_pipeline():\n  # Pipeline implementation...\n```\n\n\n### \n\nModel Versioning\n\nEach time you run a pipeline with a model configuration, a new model version is created. You can:\n\n#### \n\nExplicitly Name Versions\n\nCopy```\nfrom zenml import Model, pipeline\n@pipeline(\n  model=Model(\n    name=\"iris_classifier\", \n    version=\"1.0.5\"\n  )\n)\ndef training_pipeline():\n  # Pipeline implementation...\n```\n\n\n#### \n\nUse Templated Naming\n\nCopy```\nfrom zenml import Model, pipeline\n@pipeline(\n  model=Model(\n    name=\"iris_classifier\", \n    version=\"run-{run.id[:8]}\"\n  )\n)\ndef training_pipeline():\n  # Pipeline implementation...\n```\n\n\n### \n\nLinking Artifacts to Models\n\nArtifacts produced during pipeline runs can be linked to models to establish lineage and enable reuse:\n\nCopy```\nfrom zenml import step, Model\nfrom zenml.artifacts.utils import save_artifact\nimport pandas as pd\nfrom typing import Annotated\nfrom zenml.artifacts.artifact_config import ArtifactConfig\nfrom sklearn.base import ClassifierMixin\nfrom sklearn.ensemble import RandomForestClassifier\n# Example: Agent configuration step linking artifacts\n@step(model=Model(name=\"CustomerServiceAgent\", version=\"2.1.0\"))\ndef configure_agent(\n  knowledge_base: pd.DataFrame,\n  evaluation_results: dict\n) -> Annotated[dict, ArtifactConfig(\"agent_config\")]:\n  # Create agent configuration based on knowledge base and evaluations\n  agent_config = {\n    \"prompt_template\": generate_prompt_from_kb(knowledge_base),\n    \"tools\": [\"search\", \"database_query\", \"escalation\"],\n    \"performance_threshold\": evaluation_results[\"min_accuracy\"],\n    \"model_params\": {\"temperature\": 0.7, \"max_tokens\": 500}\n  }\n  # Save intermediate prompt variants\n  for variant in [\"concise\", \"detailed\", \"empathetic\"]:\n    prompt_variant = generate_prompt_variant(knowledge_base, variant)\n    save_artifact(\n      f\"prompt_template_{variant}\", \n      prompt_variant,\n      is_model_artifact=True,\n    )\n  return agent_config\n```\n\n\n### \n\nModel Promotion\n\nModel stages represent the progression of models through their lifecycle. ZenML supports the following stages:\n\n  * `staging`: Ready for final validation before production\n\n  * `production`: Currently deployed in a production environment\n\n  * `latest`: The most recent version (virtual stage)\n\n  * `archived`: No longer in use\n\n\n\n\nYou can promote models to different stages:\n\nCopy```\nfrom zenml import Model\nfrom zenml.enums import ModelStages\n# Promote a specific model version to production\nmodel = Model(name=\"iris_classifier\", version=\"1.2.3\")\nmodel.set_stage(stage=ModelStages.PRODUCTION)\n# Find latest model and promote to staging\nlatest_model = Model(name=\"iris_classifier\", version=ModelStages.LATEST)\nlatest_model.set_stage(stage=ModelStages.STAGING)\n```\n\n\n## \n\nUsing Models Across Pipelines\n\nOne of the most powerful features of ZenML's Model Control Plane is the ability to share artifacts between pipelines through models.\n\n### \n\nPattern: Model-Mediated Artifact Exchange\n\nThis pattern allows pipelines to exchange data without knowing the specific artifact IDs:\n\nCopy```\nfrom typing import Annotated\nfrom zenml import step, get_pipeline_context, pipeline, Model\nfrom zenml.enums import ModelStages\nimport pandas as pd\nfrom sklearn.base import ClassifierMixin\n@step\ndef predict(\n  model: ClassifierMixin,\n  data: pd.DataFrame,\n) -> Annotated[pd.Series, \"predictions\"]:\n  \"\"\"Make predictions using a trained model.\"\"\"\n  predictions = pd.Series(model.predict(data))\n  return predictions\n@pipeline(\n  model=Model(\n    name=\"iris_classifier\",\n    # Reference the production version\n    version=ModelStages.PRODUCTION,\n  ),\n)\ndef inference_pipeline():\n  \"\"\"Run inference using the production model.\"\"\"\n  # Get the model from the pipeline context\n  model = get_pipeline_context().model\n  # Load inference data (you'd need to implement this function)\n  inference_data = load_data()\n  # Run prediction using the trained model artifact\n  predict(\n    model=model.get_model_artifact(\"trained_model\"),\n    data=inference_data,\n  )\n```\n\n\nThis pattern enables clean separation between training and inference pipelines while maintaining a clear relationship between them.\n\n## \n\nTracking Metrics and Metadata\n\nZenML allows you to attach metadata to models, which is crucial for tracking performance, understanding training conditions, and making promotion decisions.\n\nWhile metadata tracking is available in both OSS and Pro versions through the Python SDK, visualizing and exploring model metrics through a dashboard interface is only available in ZenML Pro.\n\n### \n\nLogging Model Metadata\n\nCopy```\nfrom zenml import step, log_metadata, get_step_context\n@step\ndef evaluate_model(model, test_data):\n  \"\"\"Evaluate the model and log metrics.\"\"\"\n  predictions = model.predict(test_data)\n  # Note: You'd need to implement these metric calculation functions\n  accuracy = calculate_accuracy(predictions, test_data.target)\n  precision = calculate_precision(predictions, test_data.target)\n  recall = calculate_recall(predictions, test_data.target)\n  # Log metrics to the model\n  log_metadata(\n    metadata={\n      \"evaluation_metrics\": {\n        \"accuracy\": accuracy,\n        \"precision\": precision,\n        \"recall\": recall\n      }\n    },\n    infer_model=True, # Attaches to the model in the current step context\n  )\n# Example: Evaluate agent and log metrics\n@step\ndef evaluate_agent(agent_config, test_queries):\n  \"\"\"Evaluate the agent and log performance metrics.\"\"\"\n  responses = []\n  for query in test_queries:\n    response = agent_config.process_query(query)\n    responses.append(response)\n  # Note: You'd need to implement these agent evaluation functions\n  response_quality = calculate_response_quality(responses, test_queries)\n  response_time = calculate_avg_response_time(responses)\n  user_satisfaction = calculate_satisfaction_score(responses)\n  tool_usage_efficiency = calculate_tool_efficiency(agent_config.tools)\n  # Log agent performance metrics to the model\n  log_metadata(\n    metadata={\n      \"agent_evaluation\": {\n        \"response_quality\": response_quality,\n        \"avg_response_time_ms\": response_time,\n        \"user_satisfaction_score\": user_satisfaction,\n        \"tool_efficiency\": tool_usage_efficiency,\n        \"total_queries_evaluated\": len(test_queries)\n      },\n      \"agent_configuration\": {\n        \"prompt_template_version\": agent_config.prompt_version,\n        \"tools_enabled\": agent_config.tools,\n        \"model_temperature\": agent_config.temperature\n      }\n    },\n    infer_model=True, # Attaches to the agent model in the current step context\n  )\n```\n\n\n### \n\nFetching Model Metadata\n\nYou can retrieve logged metadata for analysis or decision-making:\n\nCopy```\nfrom zenml.client import Client\n# Get a specific model version\nmodel = Client().get_model_version(\"iris_classifier\", \"1.2.3\")\n# Access metadata\nmetrics = model.run_metadata[\"evaluation_metrics\"].value\nprint(f\"Model accuracy: {metrics['accuracy']}\")\n```\n\n\n## \n\nDeleting Models\n\nWhen a model is no longer needed, you can delete it or specific versions:\n\n### \n\nDeleting All Versions of a Model\n\nCopy```\nfrom zenml.client import Client\n# Using the Python SDK\nClient().delete_model(\"iris_classifier\")\n# Or using the CLI\n# zenml model delete iris_classifier\n```\n\n\n### \n\nDeleting a Specific Version\n\nCopy```\nfrom zenml.client import Client\n# Using the Python SDK\nClient().delete_model_version(\"model_version_id\")\n# Or using the CLI\n# zenml model version delete <MODEL_VERSION_NAME>\n```\n\n\n## \n\nBest Practices\n\n  * **Consistent Naming** : Use consistent naming conventions for models and versions\n\n  * **Rich Metadata** : Log comprehensive metadata to provide context for each model version\n\n  * **Promotion Strategy** : Develop a clear strategy for promoting models through stages\n\n  * **Model Association** : Associate pipelines with models to maintain lineage and enable artifact sharing\n\n  * **Versioning Strategy** : Choose between explicit versioning and template-based versioning based on your needs\n\n\n\n\n## \n\nConclusion\n\nThe Model Control Plane in ZenML provides a comprehensive solution for managing both traditional ML models and AI agent systems throughout their lifecycle. By properly registering, versioning, linking artifacts, and tracking metadata, you can create a transparent and reproducible workflow for your ML projects and AI agent development.\n\n**OSS vs Pro Feature Summary:**\n\n  * **ZenML OSS:** Includes all the programmatic (Python SDK) model features described in this guide\n\n  * **ZenML Pro:** Adds visual model dashboard, advanced model exploration, comprehensive metrics visualization, and integrated model lineage views\n\n\n\n\nWhether you're working on a simple classification model, a complex production ML system, or a sophisticated multi-agent AI application, ZenML's unified model management capabilities help you organize your resources and maintain clarity across your entire AI development lifecycle.\n\nPreviousMetadataNextDashboard\n\nLast updated 5 months ago\n\nWas this helpful?\n",
    "summary": null,
    "content_quality_score": null,
    "child_urls": [
        "https://docs.zenml.io/",
        "https://zenml.io",
        "https://zenml.io/slack",
        "https://cloud.zenml.io/signup",
        "https://docs.zenml.io/user-guides",
        "https://docs.zenml.io/pro",
        "https://docs.zenml.io/stacks",
        "https://docs.zenml.io/api-reference",
        "https://docs.zenml.io/sdk-reference",
        "https://docs.zenml.io/changelog",
        "https://docs.zenml.io/getting-started/installation",
        "https://docs.zenml.io/getting-started/hello-world",
        "https://docs.zenml.io/getting-started/your-first-ai-pipeline",
        "https://docs.zenml.io/getting-started/core-concepts",
        "https://docs.zenml.io/getting-started/system-architectures",
        "https://docs.zenml.io/deploying-zenml/deploying-zenml",
        "https://docs.zenml.io/deploying-zenml/connecting-to-zenml",
        "https://docs.zenml.io/deploying-zenml/upgrade-zenml-server",
        "https://docs.zenml.io/concepts/steps_and_pipelines",
        "https://docs.zenml.io/concepts/artifacts",
        "https://docs.zenml.io/concepts/stack_components",
        "https://docs.zenml.io/concepts/service_connectors",
        "https://docs.zenml.io/concepts/snapshots",
        "https://docs.zenml.io/concepts/deployment",
        "https://docs.zenml.io/concepts/containerization",
        "https://docs.zenml.io/concepts/code-repositories",
        "https://docs.zenml.io/concepts/secrets",
        "https://docs.zenml.io/concepts/environment-variables",
        "https://docs.zenml.io/concepts/tags",
        "https://docs.zenml.io/concepts/metadata",
        "https://docs.zenml.io/concepts/models",
        "https://docs.zenml.io/concepts/dashboard-features",
        "https://docs.zenml.io/concepts/templates",
        "https://docs.zenml.io/reference/community-and-content",
        "https://docs.zenml.io/reference/environment-variables",
        "https://docs.zenml.io/reference/llms-txt",
        "https://docs.zenml.io/reference/faq",
        "https://docs.zenml.io/reference/global-settings",
        "https://docs.zenml.io/reference/legacy-docs",
        "https://docs.zenml.io/concepts/models#understanding-models-in-zenml",
        "https://docs.zenml.io/concepts/models#what-is-a-zenml-model",
        "https://docs.zenml.io/concepts/models#the-model-control-plane",
        "https://docs.zenml.io/concepts/models#working-with-models",
        "https://docs.zenml.io/concepts/models#registering-a-model",
        "https://docs.zenml.io/concepts/models#model-versioning",
        "https://docs.zenml.io/concepts/models#linking-artifacts-to-models",
        "https://docs.zenml.io/concepts/models#model-promotion",
        "https://docs.zenml.io/concepts/models#using-models-across-pipelines",
        "https://docs.zenml.io/concepts/models#pattern-model-mediated-artifact-exchange",
        "https://docs.zenml.io/concepts/models#tracking-metrics-and-metadata",
        "https://docs.zenml.io/concepts/models#logging-model-metadata",
        "https://docs.zenml.io/concepts/models#fetching-model-metadata",
        "https://docs.zenml.io/concepts/models#deleting-models",
        "https://docs.zenml.io/concepts/models#deleting-all-versions-of-a-model",
        "https://docs.zenml.io/concepts/models#deleting-a-specific-version",
        "https://docs.zenml.io/concepts/models#best-practices",
        "https://docs.zenml.io/concepts/models#conclusion",
        "https://docs.zenml.io/concepts",
        "https://zenml.io/pro",
        "https://docs.zenml.io/concepts/models#using-the-python-sdk",
        "https://docs.zenml.io/concepts/models#using-the-cli",
        "https://docs.zenml.io/concepts/models#using-a-pipeline",
        "https://docs.zenml.io/concepts/models#explicitly-name-versions",
        "https://docs.zenml.io/concepts/models#use-templated-naming",
        "https://github.com/zenml-io/zenml",
        "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=5aBlTJNbVDkrxJp7J1J9"
    ]
}